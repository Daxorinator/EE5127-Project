\documentclass[conference]{IEEEtran}

\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage[table,xcdraw]{xcolor}
\usepackage{listings}

\usepackage{url}
\usepackage[colorlinks=true]{hyperref}

\lstdefinestyle{pythonstyle}{
	language=Python,
	basicstyle=\ttfamily\small,
	keywordstyle=\color{blue},
	commentstyle=\color{gray},
	stringstyle=\color{teal},
	showstringspaces=false,
	frame=single
}

\lstset{style=pythonstyle}

\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
		T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

\begin{document}
	
	\title{Human Activity Recognition Using Smartphone Sensor Data: Analysis and Classification using Azure ML and Power BI
	}
	
	\author{\IEEEauthorblockN{Séamus Knightly}
		\IEEEauthorblockA{\textit{1MECE1} \\
			\textit{University Of Galway}\\
			Galway, Ireland\\
			s.knightly1@universityofgalway.ie}
		\and
		\IEEEauthorblockN{Seán Kelly}
		\IEEEauthorblockA{\textit{1MECE1} \\
			\textit{University Of Galway}\\
			Galway, Ireland \\
			s.kelly178@universityofgalway.ie}
	}
	
	\maketitle
	
	\begin{abstract}
		blah blah
	\end{abstract}
	
	\begin{IEEEkeywords}
		IoT, Remote Patient Monitoring, Accelerometer, Gyroscope, Classification, Assisted Living
	\end{IEEEkeywords}
	
	\section{Introduction}
	
	Human Activity Recognition (HAR) is an important area in the domain of machine learning and medical computing. The focus is the identification and classification of human physical activities based on provided sensor data. The data can be collecte by a wide range of devices, from stationary room sensing video or radar that can monitor multiple subjects, to wearable or mobile devices that can monitor individual subjects. HAR has become an important component in applications such as remote patient monitoring and assisted living.  
	
	There are a number of large, labelled datasets available for human activity recognition. For this project, the \textit{Human Activity Recognition Using Smartphones} dataset \cite{reyes2013har} was chosen. This dataset contains sensor data collected from smartphone accelerometers and gyroscopes as participants performed activities such walking, sitting, and standing. The observations are represented by multiple time and frequency features extracted from the motion signals. Sensor signals from the device’s accelerometer and gyroscope were recorded at 50~Hz and processed into 561 time and frequency features.
	
	This dataset was chosen over other datasets, such as HARTH dataset \cite{logacjov2021harth} \cite{bach2021classifier} for its simplicity, requiring only 1 worn sensor. And for the simpler set of classifications, which correspond better with scenarios that would arise in a care facility or other healthcare setting.
	
	This paper aims to analyse and classify human activities using the UCI HAR dataset by developing and evaluating multiple machine learning models in Azure Machine Learning Studio. Power BI is employed to visualize data characteristics, feature distributions, and model performance metrics. The results provide insights into the role of sensor based data and machine learning in Human Activity Recognition.

	The introductory paper \cite{anguita2013public} demonstrated that a multiclass Support Vector Machine (SVM) model could achieve an overall classification accuracy of 96\% on this dataset, comparable to or exceeding the performance of systems using specialised wearable sensors. Their work highlighted the feasibility of using simpler accelerometer and gyroscope sensors, such as smart phones, as unobtrusive, affordable, and reliable sensing tools for HAR.
	
	\section{Dataset Description}
	
	\subsection{Dataset Source}
	
	The dataset used in this study is the \textit{Human Activity Recognition Using Smartphones} dataset \cite{reyes2013har}, first introduced in 2013. It was created as part of a study on human centered computing at the University of Genova and the Universitat Politècnica de Catalunya \cite{anguita2013public}. The dataset consists of sensor data collected from 30 volunteers aged between 19 and 48 years, performing six basic activities of daily living.
	
	Each participant carried a Samsung Galaxy S~II smartphone on the waist while performing the activities. The smartphone's embedded triaxial accelerometer and gyroscope were used to capture linear acceleration and angular velocity at a constant sampling rate of 50~Hz. The experiment was carried out in a controlled laboratory environment, with participants following a standardised sequence of activities to ensure consistency across samples. The signals were normalised and bounded within 
	[1, -1], and each feature vector is also standardised. 
	
	The dataset is publicly available from the UCI Machine Learning Repository under an open license. 

	\subsection{Feature Overview}
	
	The dataset provides both raw sensor readings and pre-processed feature vectors based on that raw data. Each observation represents a 2.56~second window of sensor data with 50\% overlap between adjacent windows, there are 128 readings per window. From each window, 561 features were extracted from the time and frequency domains.
	
	The features include statistical and signal based measures such as mean, standard deviation, median absolute deviation, signal magnitude area, and correlation between sensor axes. Frequency domain features were obtained using Fast Fourier Transform (FFT) on the windowed signals. These features capture important motion characteristics for each activity and are normalised to ensure comparability across subjects and sessions.

	Additionally, subject identifiers (1–30) are included, allowing for subject specific or subject independent analysis.
	
	In the dataset, each of the recorded activities is encoded numerically as follows: 
	1–\textit{Walking}, 2–\textit{Walking Upstairs}, 3–\textit{Walking Downstairs}, 
	4–\textit{Sitting}, 5–\textit{Standing}, and 6–\textit{Laying}.


	\subsection{Data Preparation}\label{data_preparation}
	
	Prior to model training, a subset of the original dataset features was selected to simplify the analysis and reduce computational overhead. The full UCI HAR dataset contains 561 features derived from both time and frequency transformations. This feature set provides detailed motion characterisation, but it is computationally expensive to process, particularly on the edge in the Rasbperry Pi. 
	
	To address this, a representative subset of features was selected, focusing on descriptive statistics (mean, maximum, and minimum values) from the accelerometer and gyroscope signals in both body and gravity components.
	

	The retained features include the following categories:
	\begin{itemize}
		\item \textbf{Time domain features:} body acceleration, body acceleration jerk, gyroscope, and gyroscope jerk (mean, max, and min for each axis)
		\item \textbf{Magnitude features:} signal magnitude for acceleration, jerk, and gyroscope signals
		\item \textbf{Frequency domain features:} selected mean, max, and min values for acceleration, jerk, and gyroscope signals
	\end{itemize}
	
	This reduced dataset comprises 101 variables in total. This reduction improves computational efficiency on the edge where limited processing power and energy consumption are key considerations.
	
	The original study \cite{anguita2013public} employed a Support Vector Machine (SVM) classifier, which required extensive pre-processed features to achieve high accuracy.  This work explores more modern machine learning techniques capable of capturing non-linear relationships and implicit feature interactions. It is therefore expected that the reliance on an extensive set of features is reduced without sacrificing accuracy.
	
	On the Azure Machine Learning side, the \texttt{subject} feature was excluded from model training to prevent the classifier from learning participant specific patterns.

	
	\section{Data Analysis}
	
	\subsection{Data Characteristics}
	
	The class distribution, illustrated in Fig.~\ref{fig:activity-count}, shows that the dataset is generally well balanced across the six activity categories. Each activity contains roughly a similar number of samples, ensuring that the classification problem is not significantly biased toward any single class. 
	
	\begin{figure}[t]
		\centering
		\includegraphics[width=\linewidth]{figures/activity_count_bar_chart.png}
		\caption{Distribution of recorded samples across the six activity classes.}
		\label{fig:activity-count}
	\end{figure}

	
	Figure \ref{fig:gyro-acc-scatter} plots the mean gyroscope signal along the X-axis against the corresponding mean accelerometer signal. The data forms a horizontally elongated cluster centered near 0.25 on the gyroscope axis and 0 on the accelerometer axis. This indicates that angular velocity varies more widely across activities than linear acceleration. The limited vertical spread reflects the fact that participants do not remain perfectly upright.
	The positive offset of the gyroscope mean likely arises because most activities involve forward body motion.
	\begin{figure}[t]
		\centering
		\includegraphics[width=\linewidth]{figures/scatter_plot_gyro_v_mean.png}
		\caption{Scatter plot showing the relationship between the mean body gyroscope signal (\texttt{tBodyGyro-mean()-X}) and the mean body acceleration signal (\texttt{tBodyAcc-mean()-X}).}
		\label{fig:gyro-acc-scatter}
	\end{figure}
	
	Figure~\ref{fig:feature-histograms} shows the distributions of several representative accelerometer and gyroscope mean features. 
	The features are bounded within $[-1, 1]$, confirming that normalisation was applied to the dataset to remove sensor bias and ensure comparable scaling across variables. 
	The histograms verify that the dataset is in a state suitable for machine learning analysis.
	
	The frequency domain gyroscope features (\texttt{fBodyGyro-mean()-X} and \texttt{fBodyGyro-mean()-Z}) in the top left of Fig.~\ref{fig:feature-histograms} display a wedge shaped distribution, in contrast to the more symmetric time domain features. Reflecting the characteristics of magnitudes produced by the Fast Fourier Transform, low frequency components appear more consistently, and high frequency components occur less frequently but with greater variability. 

	The data shows a complementary relationship between time and frequency domain, with time features capturing instantaneous motion and orientation, frequency features show periodicity and energy characteristics. Including both will give the model better information about the motion patterns.
	
	\begin{figure}[t]
		\centering
		\includegraphics[trim=10 95 10 50,clip,width=\linewidth]{figures/histograms.pdf}
		\caption{Histograms of representative accelerometer and gyroscope mean features, showing that all sensor readings are centered near zero and lie within the normalized range of $[-1, 1]$.}
		\label{fig:feature-histograms}
	\end{figure}

	\subsection{Trends and Patterns}
	
	Figure~\ref{fig:feature-heatmap} illustrates the mean body acceleration and gyroscope signals across all activities.
	The mean acceleration values are relatively uniform across classes, reflecting the normalisation of sensor data and the short, steady recording intervals.
	Subtle variations are visible in the gyroscope means, particularly along the Z-axis, corresponding to torso rotation and orientation differences during activities such as walking or laying.
	These differences are expected given that the device was worn at the waist, where small postural changes and rotational motion are captured more strongly in the gyroscope signals.
	Overall, the heatmap confirms that the dataset’s body motion features capture the small variations between activity types.
	
	\begin{figure}[t]
		\centering
		\includegraphics[width=\linewidth]{figures/heatmap.png}
		\caption{Heatmap of selected mean accelerometer and gyroscope features across activity classes. Dynamic activities show higher mean magnitudes than static postures.}
		\label{fig:feature-heatmap}
	\end{figure}

	
	\subsection{Feature Comparison}
	
	Figure~\ref{fig:feature-grouped-bar} compares the mean magnitudes of selected motion features across all activity classes. 
	These features, including the body acceleration magnitude (\texttt{tBodyAccMag-mean()}), gyroscope magnitude (\texttt{tBodyGyroMag-mean()}), and jerk-derived magnitudes, represent the overall intensity of body motion.
	
	A separation is visible between dynamic and static activities. 
	\textit{Walking}, \textit{Walking Upstairs}, and \textit{Walking Downstairs} (classes 1–3) exhibit notably higher magnitude values across all features, indicating stronger overall motion and rotational activity. 
	Among these, \textit{Walking Downstairs} shows significantly higher jerk magnitudes, reflecting the more abrupt deceleration and impact forces during descent. 
	
	In contrast, static postures such as \textit{Sitting}, \textit{Standing}, and \textit{Laying} (classes 4–6) display consistently lower mean magnitudes across all sensors. 
	The near zero variation among these static classes suggests limited body movement and stable device orientation. 
	These results confirm that magnitude based features can capture the motion intensity of each activity and give discriminative information for classification.
	
	\begin{figure}[t]
		\centering
		\includegraphics[width=\linewidth]{figures/feature_grouped_bar.png}
		\caption{Comparison of mean motion magnitude features across activities. Dynamic activities exhibit higher overall intensity than static postures.}
		\label{fig:feature-grouped-bar}
	\end{figure}

	
	\subsection{Box Plot Analysis}
	
	Box plots were generated to compare the distributions of selected features across activity categories (Fig.~\ref{fig:boxplot-accmag}). 
	The mean body acceleration magnitude (\texttt{tBodyAccMag-mean()}) has a clear separation between static and dynamic activities. 
	Static postures, \textit{Standing}, \textit{Sitting}, and \textit{Laying}, cluster tightly around $-1$, indicating near zero net body acceleration after gravity removal. 
	In contrast, dynamic activities (\textit{Walking}, \textit{Walking Upstairs}, and \textit{Walking Downstairs}) show higher medians and broader interquartile ranges, as they have higher motion intensity and variation.
	
	For the dynamic categories, \textit{Walking Downstairs} shows the highest median acceleration magnitude, while \textit{Walking Upstairs} has the greatest spread, consistent with the more irregular motion of climbing. 
	Although this feature alone distinguishes static from dynamic activities, the overlap between static classes (e.g., \textit{Sitting} and \textit{Standing}) suggests that multiple features are required for finer classification.
	
	\begin{figure}[t]
		\centering
		\includegraphics[width=\linewidth]{figures/boxplot_tBodyAccMag.png}
		\caption{Box plot of mean body acceleration magnitude (\texttt{tBodyAccMag-mean()}) across activity classes. Generated with Matplotlib as Box Plot methods on Power BI Online would not work.}
		\label{fig:boxplot-accmag}
	\end{figure}

	
	\subsection{Findings and Discussion}
	
	The data analysis highlights several meaningful trends across the dataset. 
	First, the activity classes are well balanced, ensuring that subsequent classification experiments are not biased toward any single class. 
	Normalisation has been applied to remove sensor bias and facilite comparison across variables. 
	
	Feature comparisons show separations between static and dynamic activities across both time and frequency domains. 
	Accelerometer features mostly capture translational body motion, making them effective for distinguishing movement, while gyroscope features show the rotation, which separates similar patterns such as \textit{Walking Upstairs} and \textit{Walking Downstairs}. 
	Frequency features provide extra information about periodicity and energy of movement, which will be useful for classification.
	
	As a whole, the data analysis confirms that the selected features make sense, are physically interpretable, and have distinct patterns across activity classes. 
	These characteristics make the dataset suitable for supervised machine learning models in Azure ML studio.

	
	
	\section{Machine Learning Model Development and Evaluation}
	
	Machine learning models were developed and evaluated in Microsoft Azure ML Studio using the processed dataset described in Section \ref{data_preparation}. A multi-class classification problem was defined, where the target label corresponds to one of six human activity classes. All models were trained using an 70/30 train–test split, and performance was assessed through the use of the \texttt{Evaluate Model} component in ML Studio.
	
	The experiments were conducted according to the project specification.
	
	\subsection{Single Feature Models}
	
	In the first experiment, 99 models were trained using a single feature each from the dataset. This was done using the \textit{Execute Python Script} component in Azure ML Studio, which was useful to automate the mass training and testing of the models. Logistic Regression was used for all, the code for this can be found in Appendix~\ref{single_feature}
	
	The resulting accuracies ranged from $\approx$17\%, roughly equivalent to a random choice, to $\approx$ 52\%, depending on the selected feature. The most informative features were primarily derived from mean accelerometer and gyroscope signals in the time domain, specifically:
	\texttt{fBodyAcc-max()-X}, \texttt{tGravityAcc-min()-Y}, \texttt{tGravityAcc-mean()-Y},
	\texttt{tGravityAcc-max()-Y}, \texttt{tBodyAcc-max()-X}, and \texttt{fBodyGyro-max()-X}.
	These activities had accuracies around $\approx$ 50\%, With Gravity related features being over-represented. This matches the physical expectation however, as these features will distinguish the static and dynamic categories. This instantly gives a boost as it reduces the chance to 1 in 3 on a random choice as 3 of the 6 activities are dynamic.
	
	The top performing single feature model achieved an accuracy of approximately 52.18\%, using \texttt{fBodyAcc-max()-X}. This indicates that horizontal body acceleration alone carries substantial information about activity state, but cannot independently distinguish similar postures such as \textit{Sitting} and \textit{Standing}.
	
	The weakest performing feature was \texttt{tBodyAcc-mean()-Y}, which achieved only 17.1\% accuracy, which is roughly equivalent to random guessing on the 6 activities. This feature captures minimal variation between activities because the Y-axis component of linear acceleration is effected by the constant gravitational force of the earth.
	
	\subsection{Combination of Features}
	
	In the second experiment, a small representative subset of features was used to evaluate how combining motion signals from multiple axes influences classification performance. The selected features represent the mean time domain linear acceleration and angular velocity along the three body axes:
	
	\begin{itemize}
		\item \texttt{tBodyAcc-mean()-X}, \texttt{tBodyAcc-mean()-Y}, \texttt{tBodyAcc-mean()-Z}
		\item \texttt{tBodyGyro-mean()-X}, \texttt{tBodyGyro-mean()-Y}, \texttt{tBodyGyro-mean()-Z}
	\end{itemize}
	
	These six features were chosen because they correspond directly to the type of raw sensor readings that would be available on a typical IoT edge device.
	
	A \textit{Multiclass Logistic Regression} classifier was trained using this six-dimensional feature set. The resulting model achieved test accuracy, precision, and recall values of approximately 27\%, a poor improvement above random guessing. This relatively poor performance indicates that while these features capture fundamental movement patterns, they do not provide sufficient discriminatory information on their own to differentiate between activities.
	
    The limited accuracy can be attributed to several factors. Firstly, mean values omit temporal variation and frequency information that are important for distinguishing activities with similar average motion but different periodic structures, like \textit{Walking Upstairs} and \textit{Walking Downstairs}. Secondly, Logistic Regression, being a linear model, is not able to capture the non linear interactions between accelerometer and gyroscope signals that make up complex human movements, however, incorporating additional derived features like signal magnitude, minimum and maximum values, and frequency domain statistics, can bring out and encode some of these non linear relationships, allowing linear models to achieve improved performance.
	
	\subsection{All Features}
	
	In the third experiment, all 99 available features in the dataset were used to train a \textit{Multiclass Logistic Regression} classifier. This configuration represents the upper bound of model performance using the full set of derived accelerometer and gyroscope features, including both time and frequency statistics such as mean, standard deviation, magnitude, and energy. These features better capture the motion characteristics of human activity.
	
	The trained model achieved an overall test accuracy of 92.8\%, with Micro Precision and Micro Recall values of 0.928, and Macro Precision and Macro Recall values of approximately 0.931 and 0.930, respectively. These results indicate good performance across all six activity classes.
	
	Compared to the previous experiments, the improvement in accuracy demonstrates the importance of including the set of pre-processed features. As discussed previously, the additional features expose the non-linear relationships in the motion signals.
	
	This experiment highlights that high performance can be achieved even with a relatively simple classification algorithm when a sufficiently rich feature set is provided. In IoT, this emphasises the benefit of performing lightweight feature extraction either on the gateway or in the cloud, rather than attempting classification directly on limited raw sensor data at the edge.
	
	\subsection{Feature Selection Methods}
	
	To reduce dimensionality and identify the most informative features, three selection techniques were evaluated in Azure ML Studio: \textit{Permutation Feature Importance}, and \textit{Filter Based Feature Selection} using the \textit{Pearson Correlation} and \textit{Chi-Squared} criteria (using a \texttt{Permutation Feature Importance} component and \texttt{Filter Based Feature Selection} components) Each method was followed by model retraining to assess its effect on performance.
	
	\textbf{Permutation Feature Importance (PFI)} was applied using a trained \textit{Multiclass Decision Forest}, achieving an accuracy of 96.1\%. The most influential features included \texttt{tGravityAcc-min()-X}, \texttt{tGravityAcc-min()-Y}, \texttt{tBodyAcc-max()-X}, and \texttt{fBodyAccMag-max()}.
	
	Using \textbf{Filter Based Selection}, the \textit{Pearson Correlation} method selected ten features with the highest linear correlation to activity class, achieving 59.6\% accuracy. In contrast, the \textit{Chi-Squared} method achieved a higher accuracy of 81.7\%, identifying both time and frequency domain features such as \texttt{tBodyAcc-max()-X}, \texttt{tGravityAccMag-max()}, and \texttt{fBodyAccMag-mean()} as most relevant.
	
	A summary of results is given in Table~\ref{tab:feature-selection-results}. The PFI method with a Decision Forest provided the best overall accuracy. Chi-Squared filtering offered a good compromise between simplicity and accuracy, making it suitable for resource limited IoT applications.
	
	\begin{table}[t]
		\caption{Feature selection method performance summary.}
		\label{tab:feature-selection-results}
		\centering
		\begin{tabular}{|l|c|}
			\hline
			\textbf{Method} & \textbf{Accuracy (\%)} \\ \hline
			Permutation Feature Importance (Decision Forest) & 96.1 \\ \hline
			Filter Based (Pearson Correlation) & 59.6 \\ \hline
			Filter Based (Chi-Squared) & 81.7 \\ \hline
		\end{tabular}
	\end{table}

	
	
	\section{Results Comparison and Discussion}
	
	Table~\ref{tab:comparison-summary} summarises the performance of all experiments conducted in Azure ML Studio. The progression from single features to the full feature set demonstrates a clear relationship between feature richness, model complexity, and classification accuracy.
	
	\begin{table}[t]
		\caption{Summary of model performance across all experiments.}
		\label{tab:comparison-summary}
		\centering
		\begin{tabular}{|l|c|}
			\hline
			\textbf{Model / Feature Set} & \textbf{Accuracy (\%)} \\ \hline
			Single Feature (best: \texttt{fBodyAcc-max()-X}) & 52.2 \\ \hline
			Six Mean Features (Accelerometer + Gyroscope) & 27.0 \\ \hline
			All 99 Features (Logistic Regression) & 92.8 \\ \hline
			Filter Based (Pearson Correlation) & 59.6 \\ \hline
			Filter Based (Chi-Squared) & 81.7 \\ \hline
			Permutation Feature Importance (Decision Forest) & 96.1 \\ \hline
		\end{tabular}
	\end{table}
	
	The single-feature and small-subset experiments highlight that limited raw sensor data provide only partial information about human activity. Individual features could distinguish static from dynamic motion but failed to capture finer variations between activities such as \textit{Walking Upstairs} and \textit{Walking Downstairs}. The poor accuracy of the six-feature model (27\%) reinforces this limitation and reflects the reduced representational power of mean values that discard temporal and frequency variation.
	
	In contrast, the full feature model achieved 92.8\% accuracy, showing that the engineered features available in the dataset significantly improve separability. Derived statistical, magnitude, and frequency domain attributes expose latent non-linear relationships that even a linear classifier like Logistic Regression can exploit. This demonstrates that well-designed feature extraction can compensate for model simplicity.
	
	The feature-selection experiments further confirmed this relationship. The Chi-Squared filter retained the most relevant subset of features, achieving 81.7\% accuracy—close to the full model but with much lower dimensionality. The Pearson correlation filter, limited to linear dependencies, performed poorly at 59.6\%. The Permutation Feature Importance method, evaluated using a Decision Forest, produced the highest overall accuracy (96.1\%), reflecting the capability of ensemble models to capture non-linear feature interactions without explicit feature engineering.
	
	From an IoT system design perspective, these results highlight several key trade-offs:
	\begin{itemize}
		\item \textbf{Edge vs. Cloud Processing:} Lightweight models on raw sensor data achieve limited accuracy and are suitable only for coarse classification. More complex processing, including feature extraction and model inference, should be offloaded to a cloud platform or high-performance gateway to achieve reliable recognition.
		\item \textbf{Feature Dimensionality:} While the full 99-feature model delivers high accuracy, feature selection can substantially reduce computation and bandwidth costs with minimal performance loss—important for constrained IoT deployments.
		\item \textbf{Model Choice:} Linear models such as Logistic Regression are interpretable and efficient but limited in expressiveness. Non-linear models like Decision Forests or Neural Networks provide superior performance at the cost of higher computational load.
	\end{itemize}
	
	Overall, the experiments demonstrate that high classification accuracy in Human Activity Recognition depends primarily on the availability of informative features. Combining moderate feature selection with non-linear classifiers offers an optimal balance between computational efficiency and predictive accuracy, aligning with the design goals of scalable IoT systems.


	
	\bibliographystyle{IEEEtran}
	\bibliography{references}
	
	\onecolumn
	\appendices
	\section{Script Used for Single Feature Evaluation in \texttt{Exectute Python Script} Component}\label{single_feature}
	\begin{lstlisting}[language=Python]
	import pandas as pd
	from sklearn.model_selection import train_test_split
	from sklearn.linear_model import LogisticRegression
	from sklearn.metrics import accuracy_score
	
	# The script MUST contain a function named azureml_main
	# which is the entry point for this module.

	
	# The entry point function MUST have two input arguments.
	# If the input port is not connected, the corresponding
	# dataframe argument will be None.
	#   Param<dataframe1>: a pandas.DataFrame
	#   Param<dataframe2>: a pandas.DataFrame
	def azureml_main(dataframe1 = None, dataframe2 = None):
	
	df = dataframe1.copy() # copy dataset
	y = df['activity'] # activity is the category
	X = df.drop(columns=['activity']) # Dataset
	
	results = []
	
	# iterate over the features available
	for feature in X.columns: 
		X_single = X[[feature]]
		X_train, X_test, y_train, y_test = train_test_split(
			X_single, y, test_size=0.2, random_state=42
		)
		# Train a logistic regression model
		model = LogisticRegression(max_iter=1000)
		model.fit(X_train, y_train)
		# grab the accuracy
		acc = accuracy_score(y_test, model.predict(X_test))
		results.append({'Feature': feature, 'Accuracy': acc})
	
	results_df = pd.DataFrame(results).sort_values(by='Accuracy', ascending=False)
	
	# output the results dataframe
	return results_df,
	
	
	\end{lstlisting}

\end{document}