{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7edb2ec2",
   "metadata": {},
   "source": [
    "# Human Activity Recognition Dataset Recreation\n",
    "\n",
    "This notebook recreates the UCI HAR Dataset feature vectors (X_train.txt) from the raw Inertial Signals data.\n",
    "\n",
    "## Dataset Information\n",
    "- **Sample Rate**: 50 Hz\n",
    "- **Window Size**: 2.56 seconds (128 samples)\n",
    "- **Window Overlap**: 50% (64 samples step)\n",
    "- **Features**: 561 time and frequency domain features\n",
    "- **Activities**: WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING\n",
    "\n",
    "## Feature Categories\n",
    "1. **Time Domain**: tBodyAcc, tGravityAcc, tBodyAccJerk, tBodyGyro, tBodyGyroJerk, and their magnitudes\n",
    "2. **Frequency Domain**: FFT applied to time domain signals (prefix 'f')\n",
    "3. **Statistics**: mean, std, mad, max, min, sma, energy, iqr, entropy, arCoeff, correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a303df92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from scipy.signal import butter, filtfilt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04664997",
   "metadata": {},
   "source": [
    "## Load Raw Inertial Signals\n",
    "\n",
    "Load the 9 raw signal files from the Inertial Signals directory:\n",
    "- Body accelerometer (X, Y, Z)\n",
    "- Body gyroscope (X, Y, Z)\n",
    "- Total accelerometer (X, Y, Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a38728ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (7352, 128)\n",
      "Number of windows: 7352\n",
      "Samples per window: 128\n"
     ]
    }
   ],
   "source": [
    "# Load inertial signals\n",
    "data_dir = 'dataset/train/Inertial Signals/'\n",
    "\n",
    "# Load body accelerometer\n",
    "body_acc_x = np.loadtxt(data_dir + 'body_acc_x_train.txt')\n",
    "body_acc_y = np.loadtxt(data_dir + 'body_acc_y_train.txt')\n",
    "body_acc_z = np.loadtxt(data_dir + 'body_acc_z_train.txt')\n",
    "\n",
    "# Load body gyroscope\n",
    "body_gyro_x = np.loadtxt(data_dir + 'body_gyro_x_train.txt')\n",
    "body_gyro_y = np.loadtxt(data_dir + 'body_gyro_y_train.txt')\n",
    "body_gyro_z = np.loadtxt(data_dir + 'body_gyro_z_train.txt')\n",
    "\n",
    "# Load total accelerometer\n",
    "total_acc_x = np.loadtxt(data_dir + 'total_acc_x_train.txt')\n",
    "total_acc_y = np.loadtxt(data_dir + 'total_acc_y_train.txt')\n",
    "total_acc_z = np.loadtxt(data_dir + 'total_acc_z_train.txt')\n",
    "\n",
    "print(f\"Data shape: {body_acc_x.shape}\")\n",
    "print(f\"Number of windows: {body_acc_x.shape[0]}\")\n",
    "print(f\"Samples per window: {body_acc_x.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "786ad413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gravity acceleration calculated\n"
     ]
    }
   ],
   "source": [
    "# Calculate gravity acceleration from total acceleration\n",
    "# Gravity is the low-frequency component (< 0.3 Hz)\n",
    "def apply_gravity_filter(signal, cutoff=0.3, fs=50, order=3):\n",
    "    \"\"\"Apply low-pass Butterworth filter to extract gravity component\"\"\"\n",
    "    nyquist = 0.5 * fs\n",
    "    normal_cutoff = cutoff / nyquist\n",
    "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    return filtfilt(b, a, signal)\n",
    "\n",
    "# Calculate gravity acceleration for each window\n",
    "gravity_acc_x = np.array([apply_gravity_filter(window) for window in total_acc_x])\n",
    "gravity_acc_y = np.array([apply_gravity_filter(window) for window in total_acc_y])\n",
    "gravity_acc_z = np.array([apply_gravity_filter(window) for window in total_acc_z])\n",
    "\n",
    "print(\"Gravity acceleration calculated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6198fc2",
   "metadata": {},
   "source": [
    "## Feature Extraction Functions\n",
    "\n",
    "Define functions to calculate all 561 features for each signal window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "51623764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature extraction functions defined\n"
     ]
    }
   ],
   "source": [
    "def calculate_jerk(signal, dt=0.02):\n",
    "    \"\"\"Calculate jerk (derivative) of signal\"\"\"\n",
    "    return np.diff(signal, axis=1) / dt\n",
    "\n",
    "def calculate_magnitude(x, y, z):\n",
    "    \"\"\"Calculate Euclidean magnitude of 3D signal\"\"\"\n",
    "    return np.sqrt(x**2 + y**2 + z**2)\n",
    "\n",
    "def signal_magnitude_area(x, y, z):\n",
    "    \"\"\"Calculate signal magnitude area\"\"\"\n",
    "    return np.mean(np.abs(x) + np.abs(y) + np.abs(z), axis=1)\n",
    "\n",
    "def energy(signal):\n",
    "    \"\"\"Calculate energy: sum of squares / N\"\"\"\n",
    "    return np.mean(signal**2, axis=1)\n",
    "\n",
    "def iqr(signal):\n",
    "    \"\"\"Calculate interquartile range\"\"\"\n",
    "    return np.percentile(signal, 75, axis=1) - np.percentile(signal, 25, axis=1)\n",
    "\n",
    "def entropy(signal):\n",
    "    \"\"\"Calculate signal entropy\"\"\"\n",
    "    # Normalize signal to create probability distribution\n",
    "    signal_normalized = np.abs(signal) / (np.sum(np.abs(signal), axis=1, keepdims=True) + 1e-10)\n",
    "    # Calculate entropy\n",
    "    return -np.sum(signal_normalized * np.log(signal_normalized + 1e-10), axis=1)\n",
    "\n",
    "def arCoeff(signal, order=4):\n",
    "    \"\"\"Calculate autoregression coefficients using Burg method\"\"\"\n",
    "    from scipy.signal import lfilter\n",
    "    coeffs = []\n",
    "    for window in signal:\n",
    "        # Simple AR coefficient estimation\n",
    "        acf = np.correlate(window - np.mean(window), window - np.mean(window), mode='full')\n",
    "        acf = acf[len(acf)//2:]\n",
    "        acf = acf / acf[0]\n",
    "        ar = []\n",
    "        for i in range(1, min(order + 1, len(acf))):\n",
    "            ar.append(acf[i])\n",
    "        while len(ar) < order:\n",
    "            ar.append(0.0)\n",
    "        coeffs.append(ar[:order])\n",
    "    return np.array(coeffs)\n",
    "\n",
    "def correlation_coeff(x, y):\n",
    "    \"\"\"Calculate correlation coefficient between two signals\"\"\"\n",
    "    corr = []\n",
    "    for i in range(len(x)):\n",
    "        if np.std(x[i]) > 0 and np.std(y[i]) > 0:\n",
    "            corr.append(np.corrcoef(x[i], y[i])[0, 1])\n",
    "        else:\n",
    "            corr.append(0.0)\n",
    "    return np.array(corr)\n",
    "\n",
    "print(\"Feature extraction functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3edbb341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3D feature extraction function defined\n"
     ]
    }
   ],
   "source": [
    "def extract_features_3d(signal_x, signal_y, signal_z, prefix):\n",
    "    \"\"\"Extract time domain features for 3-axial signal\"\"\"\n",
    "    features = {}\n",
    "    \n",
    "    # Basic statistics for each axis\n",
    "    for axis, signal in [('X', signal_x), ('Y', signal_y), ('Z', signal_z)]:\n",
    "        features[f'{prefix}-mean()-{axis}'] = np.mean(signal, axis=1)\n",
    "        features[f'{prefix}-std()-{axis}'] = np.std(signal, axis=1)\n",
    "        features[f'{prefix}-mad()-{axis}'] = np.mean(np.abs(signal - np.mean(signal, axis=1, keepdims=True)), axis=1)\n",
    "        features[f'{prefix}-max()-{axis}'] = np.max(signal, axis=1)\n",
    "        features[f'{prefix}-min()-{axis}'] = np.min(signal, axis=1)\n",
    "        features[f'{prefix}-energy()-{axis}'] = energy(signal)\n",
    "        features[f'{prefix}-iqr()-{axis}'] = iqr(signal)\n",
    "        features[f'{prefix}-entropy()-{axis}'] = entropy(signal)\n",
    "    \n",
    "    # Signal magnitude area\n",
    "    features[f'{prefix}-sma()'] = signal_magnitude_area(signal_x, signal_y, signal_z)\n",
    "    \n",
    "    # Autoregression coefficients (4 per axis)\n",
    "    for axis, signal in [('X', signal_x), ('Y', signal_y), ('Z', signal_z)]:\n",
    "        ar_coeffs = arCoeff(signal, order=4)\n",
    "        for i in range(4):\n",
    "            features[f'{prefix}-arCoeff()-{axis},{i+1}'] = ar_coeffs[:, i]\n",
    "    \n",
    "    # Correlation between axes\n",
    "    features[f'{prefix}-correlation()-X,Y'] = correlation_coeff(signal_x, signal_y)\n",
    "    features[f'{prefix}-correlation()-X,Z'] = correlation_coeff(signal_x, signal_z)\n",
    "    features[f'{prefix}-correlation()-Y,Z'] = correlation_coeff(signal_y, signal_z)\n",
    "    \n",
    "    return features\n",
    "\n",
    "print(\"3D feature extraction function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b03c330f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Magnitude feature extraction function defined\n"
     ]
    }
   ],
   "source": [
    "def extract_features_magnitude(magnitude, prefix):\n",
    "    \"\"\"Extract time domain features for magnitude signal\"\"\"\n",
    "    features = {}\n",
    "    \n",
    "    features[f'{prefix}-mean()'] = np.mean(magnitude, axis=1)\n",
    "    features[f'{prefix}-std()'] = np.std(magnitude, axis=1)\n",
    "    features[f'{prefix}-mad()'] = np.mean(np.abs(magnitude - np.mean(magnitude, axis=1, keepdims=True)), axis=1)\n",
    "    features[f'{prefix}-max()'] = np.max(magnitude, axis=1)\n",
    "    features[f'{prefix}-min()'] = np.min(magnitude, axis=1)\n",
    "    features[f'{prefix}-sma()'] = np.mean(np.abs(magnitude), axis=1)\n",
    "    features[f'{prefix}-energy()'] = energy(magnitude)\n",
    "    features[f'{prefix}-iqr()'] = iqr(magnitude)\n",
    "    features[f'{prefix}-entropy()'] = entropy(magnitude)\n",
    "    \n",
    "    # Autoregression coefficients\n",
    "    ar_coeffs = arCoeff(magnitude, order=4)\n",
    "    for i in range(4):\n",
    "        features[f'{prefix}-arCoeff(){i+1}'] = ar_coeffs[:, i]\n",
    "    \n",
    "    return features\n",
    "\n",
    "print(\"Magnitude feature extraction function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d9b46cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FFT feature extraction function defined\n"
     ]
    }
   ],
   "source": [
    "def extract_fft_features_3d(signal_x, signal_y, signal_z, prefix, fs=50):\n",
    "    \"\"\"Extract frequency domain features for 3-axial signal\"\"\"\n",
    "    features = {}\n",
    "    \n",
    "    for axis, signal in [('X', signal_x), ('Y', signal_y), ('Z', signal_z)]:\n",
    "        # Apply FFT\n",
    "        fft_vals = np.fft.fft(signal, axis=1)\n",
    "        n = signal.shape[1]\n",
    "        fft_magnitude = np.abs(fft_vals)[:, :n//2]\n",
    "        freqs = np.fft.fftfreq(n, d=1/fs)[:n//2]\n",
    "        \n",
    "        # Basic statistics\n",
    "        features[f'{prefix}-mean()-{axis}'] = np.mean(fft_magnitude, axis=1)\n",
    "        features[f'{prefix}-std()-{axis}'] = np.std(fft_magnitude, axis=1)\n",
    "        features[f'{prefix}-mad()-{axis}'] = np.mean(np.abs(fft_magnitude - np.mean(fft_magnitude, axis=1, keepdims=True)), axis=1)\n",
    "        features[f'{prefix}-max()-{axis}'] = np.max(fft_magnitude, axis=1)\n",
    "        features[f'{prefix}-min()-{axis}'] = np.min(fft_magnitude, axis=1)\n",
    "        features[f'{prefix}-energy()-{axis}'] = energy(fft_magnitude)\n",
    "        features[f'{prefix}-iqr()-{axis}'] = iqr(fft_magnitude)\n",
    "        features[f'{prefix}-entropy()-{axis}'] = entropy(fft_magnitude)\n",
    "        \n",
    "        # Max index\n",
    "        features[f'{prefix}-maxInds-{axis}'] = np.argmax(fft_magnitude, axis=1)\n",
    "        \n",
    "        # Mean frequency (weighted average)\n",
    "        mean_freq = []\n",
    "        for i in range(len(fft_magnitude)):\n",
    "            total_power = np.sum(fft_magnitude[i])\n",
    "            if total_power > 0:\n",
    "                mean_freq.append(np.sum(freqs * fft_magnitude[i]) / total_power)\n",
    "            else:\n",
    "                mean_freq.append(0.0)\n",
    "        features[f'{prefix}-meanFreq()-{axis}'] = np.array(mean_freq)\n",
    "        \n",
    "        # Skewness and kurtosis\n",
    "        features[f'{prefix}-skewness()-{axis}'] = stats.skew(fft_magnitude, axis=1)\n",
    "        features[f'{prefix}-kurtosis()-{axis}'] = stats.kurtosis(fft_magnitude, axis=1)\n",
    "    \n",
    "    # Signal magnitude area\n",
    "    fft_x = np.abs(np.fft.fft(signal_x, axis=1))[:, :signal_x.shape[1]//2]\n",
    "    fft_y = np.abs(np.fft.fft(signal_y, axis=1))[:, :signal_y.shape[1]//2]\n",
    "    fft_z = np.abs(np.fft.fft(signal_z, axis=1))[:, :signal_z.shape[1]//2]\n",
    "    features[f'{prefix}-sma()'] = np.mean(fft_x + fft_y + fft_z, axis=1)\n",
    "    \n",
    "    # Band energy features (8 bands for each axis)\n",
    "    bands = [(0, 8), (8, 16), (16, 24), (24, 32), (32, 40), (40, 48), (48, 56), (56, 64),\n",
    "             (0, 16), (16, 32), (32, 48), (48, 64), (0, 24), (24, 48)]\n",
    "    \n",
    "    for axis, signal in [('X', signal_x), ('Y', signal_y), ('Z', signal_z)]:\n",
    "        fft_vals = np.fft.fft(signal, axis=1)\n",
    "        n = signal.shape[1]\n",
    "        fft_magnitude = np.abs(fft_vals)[:, :n//2]\n",
    "        \n",
    "        for start, end in bands:\n",
    "            if end <= fft_magnitude.shape[1]:\n",
    "                band_energy = np.sum(fft_magnitude[:, start:end]**2, axis=1) / (end - start)\n",
    "                features[f'{prefix}-bandsEnergy()-{start+1},{end}'] = band_energy\n",
    "    \n",
    "    return features\n",
    "\n",
    "print(\"FFT feature extraction function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "69c14a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FFT magnitude feature extraction function defined\n"
     ]
    }
   ],
   "source": [
    "def extract_fft_features_magnitude(magnitude, prefix, fs=50):\n",
    "    \"\"\"Extract frequency domain features for magnitude signal\"\"\"\n",
    "    features = {}\n",
    "    \n",
    "    # Apply FFT\n",
    "    fft_vals = np.fft.fft(magnitude, axis=1)\n",
    "    n = magnitude.shape[1]\n",
    "    fft_magnitude = np.abs(fft_vals)[:, :n//2]\n",
    "    freqs = np.fft.fftfreq(n, d=1/fs)[:n//2]\n",
    "    \n",
    "    # Basic statistics\n",
    "    features[f'{prefix}-mean()'] = np.mean(fft_magnitude, axis=1)\n",
    "    features[f'{prefix}-std()'] = np.std(fft_magnitude, axis=1)\n",
    "    features[f'{prefix}-mad()'] = np.mean(np.abs(fft_magnitude - np.mean(fft_magnitude, axis=1, keepdims=True)), axis=1)\n",
    "    features[f'{prefix}-max()'] = np.max(fft_magnitude, axis=1)\n",
    "    features[f'{prefix}-min()'] = np.min(fft_magnitude, axis=1)\n",
    "    features[f'{prefix}-sma()'] = np.mean(np.abs(fft_magnitude), axis=1)\n",
    "    features[f'{prefix}-energy()'] = energy(fft_magnitude)\n",
    "    features[f'{prefix}-iqr()'] = iqr(fft_magnitude)\n",
    "    features[f'{prefix}-entropy()'] = entropy(fft_magnitude)\n",
    "    \n",
    "    # Max index\n",
    "    features[f'{prefix}-maxInds()'] = np.argmax(fft_magnitude, axis=1)\n",
    "    \n",
    "    # Mean frequency\n",
    "    mean_freq = []\n",
    "    for i in range(len(fft_magnitude)):\n",
    "        total_power = np.sum(fft_magnitude[i])\n",
    "        if total_power > 0:\n",
    "            mean_freq.append(np.sum(freqs * fft_magnitude[i]) / total_power)\n",
    "        else:\n",
    "            mean_freq.append(0.0)\n",
    "    features[f'{prefix}-meanFreq()'] = np.array(mean_freq)\n",
    "    \n",
    "    # Skewness and kurtosis\n",
    "    features[f'{prefix}-skewness()'] = stats.skew(fft_magnitude, axis=1)\n",
    "    features[f'{prefix}-kurtosis()'] = stats.kurtosis(fft_magnitude, axis=1)\n",
    "    \n",
    "    return features\n",
    "\n",
    "print(\"FFT magnitude feature extraction function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a90735",
   "metadata": {},
   "source": [
    "## Calculate Derived Signals\n",
    "\n",
    "Calculate jerk signals and magnitudes for all sensor data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ef200256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Derived signals calculated\n",
      "Jerk signal shape: (7352, 127)\n",
      "Magnitude signal shape: (7352, 128)\n"
     ]
    }
   ],
   "source": [
    "# Calculate jerk signals (derivative of acceleration and angular velocity)\n",
    "body_acc_jerk_x = calculate_jerk(body_acc_x)\n",
    "body_acc_jerk_y = calculate_jerk(body_acc_y)\n",
    "body_acc_jerk_z = calculate_jerk(body_acc_z)\n",
    "\n",
    "body_gyro_jerk_x = calculate_jerk(body_gyro_x)\n",
    "body_gyro_jerk_y = calculate_jerk(body_gyro_y)\n",
    "body_gyro_jerk_z = calculate_jerk(body_gyro_z)\n",
    "\n",
    "# Calculate magnitudes\n",
    "body_acc_mag = calculate_magnitude(body_acc_x, body_acc_y, body_acc_z)\n",
    "gravity_acc_mag = calculate_magnitude(gravity_acc_x, gravity_acc_y, gravity_acc_z)\n",
    "body_acc_jerk_mag = calculate_magnitude(body_acc_jerk_x, body_acc_jerk_y, body_acc_jerk_z)\n",
    "body_gyro_mag = calculate_magnitude(body_gyro_x, body_gyro_y, body_gyro_z)\n",
    "body_gyro_jerk_mag = calculate_magnitude(body_gyro_jerk_x, body_gyro_jerk_y, body_gyro_jerk_z)\n",
    "\n",
    "print(\"Derived signals calculated\")\n",
    "print(f\"Jerk signal shape: {body_acc_jerk_x.shape}\")\n",
    "print(f\"Magnitude signal shape: {body_acc_mag.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95444717",
   "metadata": {},
   "source": [
    "## Extract All Features\n",
    "\n",
    "Extract all 561 features from the signals. This follows the exact feature order from features.txt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "839caa76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features...\n",
      "Extracting tBodyAcc features...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features...\n",
      "Extracting tBodyAcc features...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting tGravityAcc features...\n",
      "Extracting tBodyAccJerk features...\n",
      "Extracting tBodyAccJerk features...\n",
      "Extracting tBodyGyro features...\n",
      "Extracting tBodyGyro features...\n",
      "Extracting tBodyGyroJerk features...\n",
      "Extracting tBodyGyroJerk features...\n",
      "Extracting tBodyAccMag features...\n",
      "Extracting tGravityAccMag features...\n",
      "Extracting tBodyAccMag features...\n",
      "Extracting tGravityAccMag features...\n",
      "Extracting tBodyAccJerkMag features...\n",
      "Extracting tBodyGyroMag features...\n",
      "Extracting tBodyAccJerkMag features...\n",
      "Extracting tBodyGyroMag features...\n",
      "Extracting tBodyGyroJerkMag features...\n",
      "Time domain features extracted: 265 feature types\n",
      "Extracting tBodyGyroJerkMag features...\n",
      "Time domain features extracted: 265 feature types\n"
     ]
    }
   ],
   "source": [
    "print(\"Extracting features...\")\n",
    "all_features = {}\n",
    "\n",
    "# 1. tBodyAcc-XYZ (40 features)\n",
    "print(\"Extracting tBodyAcc features...\")\n",
    "all_features.update(extract_features_3d(body_acc_x, body_acc_y, body_acc_z, 'tBodyAcc'))\n",
    "\n",
    "# 2. tGravityAcc-XYZ (40 features)\n",
    "print(\"Extracting tGravityAcc features...\")\n",
    "all_features.update(extract_features_3d(gravity_acc_x, gravity_acc_y, gravity_acc_z, 'tGravityAcc'))\n",
    "\n",
    "# 3. tBodyAccJerk-XYZ (40 features)\n",
    "print(\"Extracting tBodyAccJerk features...\")\n",
    "all_features.update(extract_features_3d(body_acc_jerk_x, body_acc_jerk_y, body_acc_jerk_z, 'tBodyAccJerk'))\n",
    "\n",
    "# 4. tBodyGyro-XYZ (40 features)\n",
    "print(\"Extracting tBodyGyro features...\")\n",
    "all_features.update(extract_features_3d(body_gyro_x, body_gyro_y, body_gyro_z, 'tBodyGyro'))\n",
    "\n",
    "# 5. tBodyGyroJerk-XYZ (40 features)\n",
    "print(\"Extracting tBodyGyroJerk features...\")\n",
    "all_features.update(extract_features_3d(body_gyro_jerk_x, body_gyro_jerk_y, body_gyro_jerk_z, 'tBodyGyroJerk'))\n",
    "\n",
    "# 6. tBodyAccMag (13 features)\n",
    "print(\"Extracting tBodyAccMag features...\")\n",
    "all_features.update(extract_features_magnitude(body_acc_mag, 'tBodyAccMag'))\n",
    "\n",
    "# 7. tGravityAccMag (13 features)\n",
    "print(\"Extracting tGravityAccMag features...\")\n",
    "all_features.update(extract_features_magnitude(gravity_acc_mag, 'tGravityAccMag'))\n",
    "\n",
    "# 8. tBodyAccJerkMag (13 features)\n",
    "print(\"Extracting tBodyAccJerkMag features...\")\n",
    "all_features.update(extract_features_magnitude(body_acc_jerk_mag, 'tBodyAccJerkMag'))\n",
    "\n",
    "# 9. tBodyGyroMag (13 features)\n",
    "print(\"Extracting tBodyGyroMag features...\")\n",
    "all_features.update(extract_features_magnitude(body_gyro_mag, 'tBodyGyroMag'))\n",
    "\n",
    "# 10. tBodyGyroJerkMag (13 features)\n",
    "print(\"Extracting tBodyGyroJerkMag features...\")\n",
    "all_features.update(extract_features_magnitude(body_gyro_jerk_mag, 'tBodyGyroJerkMag'))\n",
    "\n",
    "print(f\"Time domain features extracted: {len(all_features)} feature types\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "96afc2a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting fBodyAcc features...\n",
      "Extracting fBodyAccJerk features...\n",
      "Extracting fBodyAccJerk features...\n",
      "Extracting fBodyGyro features...\n",
      "Extracting fBodyGyro features...\n",
      "Extracting fBodyAccMag features...\n",
      "Extracting fBodyBodyAccJerkMag features...\n",
      "Extracting fBodyAccMag features...\n",
      "Extracting fBodyBodyAccJerkMag features...\n",
      "Extracting fBodyBodyGyroMag features...\n",
      "Extracting fBodyBodyGyroJerkMag features...\n",
      "Extracting fBodyBodyGyroMag features...\n",
      "Extracting fBodyBodyGyroJerkMag features...\n",
      "Total features extracted: 468 feature types\n",
      "Total features extracted: 468 feature types\n"
     ]
    }
   ],
   "source": [
    "# 11. fBodyAcc-XYZ (79 features per axis = 237 + 14 bands per axis)\n",
    "print(\"Extracting fBodyAcc features...\")\n",
    "all_features.update(extract_fft_features_3d(body_acc_x, body_acc_y, body_acc_z, 'fBodyAcc'))\n",
    "\n",
    "# 12. fBodyAccJerk-XYZ (79 features per axis)\n",
    "print(\"Extracting fBodyAccJerk features...\")\n",
    "all_features.update(extract_fft_features_3d(body_acc_jerk_x, body_acc_jerk_y, body_acc_jerk_z, 'fBodyAccJerk'))\n",
    "\n",
    "# 13. fBodyGyro-XYZ (79 features per axis)\n",
    "print(\"Extracting fBodyGyro features...\")\n",
    "all_features.update(extract_fft_features_3d(body_gyro_x, body_gyro_y, body_gyro_z, 'fBodyGyro'))\n",
    "\n",
    "# 14. fBodyAccMag (13 features)\n",
    "print(\"Extracting fBodyAccMag features...\")\n",
    "all_features.update(extract_fft_features_magnitude(body_acc_mag, 'fBodyAccMag'))\n",
    "\n",
    "# 15. fBodyAccJerkMag (13 features)\n",
    "print(\"Extracting fBodyBodyAccJerkMag features...\")\n",
    "all_features.update(extract_fft_features_magnitude(body_acc_jerk_mag, 'fBodyBodyAccJerkMag'))\n",
    "\n",
    "# 16. fBodyGyroMag (13 features)\n",
    "print(\"Extracting fBodyBodyGyroMag features...\")\n",
    "all_features.update(extract_fft_features_magnitude(body_gyro_mag, 'fBodyBodyGyroMag'))\n",
    "\n",
    "# 17. fBodyGyroJerkMag (13 features)\n",
    "print(\"Extracting fBodyBodyGyroJerkMag features...\")\n",
    "all_features.update(extract_fft_features_magnitude(body_gyro_jerk_mag, 'fBodyBodyGyroJerkMag'))\n",
    "\n",
    "print(f\"Total features extracted: {len(all_features)} feature types\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd73d2f",
   "metadata": {},
   "source": [
    "## Create Feature DataFrame\n",
    "\n",
    "Combine all features into a DataFrame following the exact order from features.txt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "652f6b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected number of features: 561\n",
      "Warning: Feature 'fBodyAccJerk-bandsEnergy()-57,64' not found, using zeros\n",
      "Warning: Feature 'fBodyAccJerk-bandsEnergy()-49,64' not found, using zeros\n",
      "Warning: Feature 'fBodyAccJerk-bandsEnergy()-57,64' not found, using zeros\n",
      "Warning: Feature 'fBodyAccJerk-bandsEnergy()-49,64' not found, using zeros\n",
      "Warning: Feature 'fBodyAccJerk-bandsEnergy()-57,64' not found, using zeros\n",
      "Warning: Feature 'fBodyAccJerk-bandsEnergy()-49,64' not found, using zeros\n",
      "Warning: Feature 'fBodyAccMag-maxInds' not found, using zeros\n",
      "Warning: Feature 'fBodyBodyAccJerkMag-maxInds' not found, using zeros\n",
      "Warning: Feature 'fBodyBodyGyroMag-maxInds' not found, using zeros\n",
      "Warning: Feature 'fBodyBodyGyroJerkMag-maxInds' not found, using zeros\n",
      "Warning: Feature 'angle(tBodyAccMean,gravity)' not found, using zeros\n",
      "Warning: Feature 'angle(tBodyAccJerkMean),gravityMean)' not found, using zeros\n",
      "Warning: Feature 'angle(tBodyGyroMean,gravityMean)' not found, using zeros\n",
      "Warning: Feature 'angle(tBodyGyroJerkMean,gravityMean)' not found, using zeros\n",
      "Warning: Feature 'angle(X,gravityMean)' not found, using zeros\n",
      "Warning: Feature 'angle(Y,gravityMean)' not found, using zeros\n",
      "Warning: Feature 'angle(Z,gravityMean)' not found, using zeros\n",
      "Recreated dataset shape: (7352, 561)\n",
      "Expected shape: (7352, 561)\n"
     ]
    }
   ],
   "source": [
    "# Load the feature names from features.txt to ensure correct order\n",
    "feature_names = []\n",
    "with open('dataset/features.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        parts = line.strip().split()\n",
    "        if len(parts) >= 2:\n",
    "            feature_names.append(' '.join(parts[1:]))\n",
    "\n",
    "print(f\"Expected number of features: {len(feature_names)}\")\n",
    "\n",
    "# Create DataFrame with features in the correct order\n",
    "feature_data = []\n",
    "for feature_name in feature_names:\n",
    "    if feature_name in all_features:\n",
    "        feature_data.append(all_features[feature_name])\n",
    "    else:\n",
    "        # If feature not found, use zeros\n",
    "        print(f\"Warning: Feature '{feature_name}' not found, using zeros\")\n",
    "        feature_data.append(np.zeros(body_acc_x.shape[0]))\n",
    "\n",
    "# Transpose to get windows as rows, features as columns\n",
    "X_train_recreated = np.array(feature_data).T\n",
    "\n",
    "print(f\"Recreated dataset shape: {X_train_recreated.shape}\")\n",
    "print(f\"Expected shape: ({body_acc_x.shape[0]}, 561)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7564b70e",
   "metadata": {},
   "source": [
    "## Normalize Features\n",
    "\n",
    "Normalize all features to [-1, 1] range to match the original UCI HAR dataset format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "63f8b3c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizing features to [-1, 1] range...\n",
      "Normalized dataset shape: (7352, 561)\n",
      "Min value: -1.000000\n",
      "Max value: 1.000000\n"
     ]
    }
   ],
   "source": [
    "# Normalize each feature to [-1, 1] range\n",
    "print(\"Normalizing features to [-1, 1] range...\")\n",
    "\n",
    "X_train_normalized = np.zeros_like(X_train_recreated)\n",
    "\n",
    "for i in range(X_train_recreated.shape[1]):\n",
    "    feature_values = X_train_recreated[:, i]\n",
    "    min_val = np.min(feature_values)\n",
    "    max_val = np.max(feature_values)\n",
    "    \n",
    "    # Avoid division by zero\n",
    "    if max_val - min_val > 1e-10:\n",
    "        # Normalize to [-1, 1]\n",
    "        X_train_normalized[:, i] = 2 * (feature_values - min_val) / (max_val - min_val) - 1\n",
    "    else:\n",
    "        # If all values are the same, set to 0\n",
    "        X_train_normalized[:, i] = 0\n",
    "\n",
    "print(f\"Normalized dataset shape: {X_train_normalized.shape}\")\n",
    "print(f\"Min value: {np.min(X_train_normalized):.6f}\")\n",
    "print(f\"Max value: {np.max(X_train_normalized):.6f}\")\n",
    "\n",
    "# Update the main variable\n",
    "X_train_recreated = X_train_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c79e6aa",
   "metadata": {},
   "source": [
    "## Save Normalization Parameters\n",
    "\n",
    "Save the min/max values for each feature so they can be used in real-time normalization in main.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6a9b1e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving normalization parameters...\n",
      "Normalization parameters saved to normalization_params.json\n",
      "\n",
      "Total features: 477\n",
      "\n",
      "First 10 normalization parameters:\n",
      "tBodyAcc-mean()-X:\n",
      "  min: -0.263284, max: 0.148878\n",
      "tBodyAcc-mean()-Y:\n",
      "  min: -0.515524, max: 0.533502\n",
      "tBodyAcc-mean()-Z:\n",
      "  min: -0.294562, max: 0.366119\n",
      "tBodyAcc-std()-X:\n",
      "  min: 0.001413, max: 0.648675\n",
      "tBodyAcc-std()-Y:\n",
      "  min: 0.001748, max: 0.327796\n",
      "tBodyAcc-std()-Z:\n",
      "  min: 0.003014, max: 0.361280\n",
      "tBodyAcc-mad()-X:\n",
      "  min: 0.001122, max: 0.569274\n",
      "tBodyAcc-mad()-Y:\n",
      "  min: 0.001294, max: 0.273391\n",
      "tBodyAcc-mad()-Z:\n",
      "  min: 0.002383, max: 0.287403\n",
      "tBodyAcc-max()-X:\n",
      "  min: -0.032683, max: 1.299912\n",
      "\n",
      "Normalization formula: normalized = 2 * (value - min) / (max - min) - 1\n",
      "\n",
      "Normalization code saved to normalization_params.py\n",
      "\n",
      "Usage in main.py:\n",
      "  from normalization_params import normalize_feature, NORMALIZATION_PARAMS\n",
      "  normalized_value = normalize_feature(raw_value, 'tBodyAcc-mean()-X')\n",
      "\n",
      "IMPORTANT: Make sure to convert accelerometer from m/s² to g's first!\n",
      "  acceleration_g = acceleration_ms2 / 9.80665\n"
     ]
    }
   ],
   "source": [
    "# Save normalization parameters for real-time use\n",
    "print(\"Saving normalization parameters...\")\n",
    "\n",
    "# Create a dictionary to store min and max values for each feature\n",
    "normalization_params = {}\n",
    "\n",
    "for i, feature_name in enumerate(feature_names):\n",
    "    feature_values = np.array(feature_data[i])\n",
    "    \n",
    "    min_val = np.min(feature_values)\n",
    "    max_val = np.max(feature_values)\n",
    "    \n",
    "    normalization_params[feature_name] = {\n",
    "        'min': float(min_val),\n",
    "        'max': float(max_val),\n",
    "        'feature_index': i\n",
    "    }\n",
    "\n",
    "# Save to JSON file for easy loading in main.py\n",
    "import json\n",
    "\n",
    "output_file_json = 'normalization_params.json'\n",
    "with open(output_file_json, 'w') as f:\n",
    "    json.dump(normalization_params, f, indent=2)\n",
    "\n",
    "print(f\"Normalization parameters saved to {output_file_json}\")\n",
    "print(f\"\\nTotal features: {len(normalization_params)}\")\n",
    "\n",
    "# Display first few parameters\n",
    "print(\"\\nFirst 10 normalization parameters:\")\n",
    "for i, (feature_name, params) in enumerate(list(normalization_params.items())[:10]):\n",
    "    print(f\"{feature_name}:\")\n",
    "    print(f\"  min: {params['min']:.6f}, max: {params['max']:.6f}\")\n",
    "\n",
    "print(\"\\nNormalization formula: normalized = 2 * (value - min) / (max - min) - 1\")\n",
    "\n",
    "# Also save as Python code for direct inclusion\n",
    "output_code_file = 'normalization_params.py'\n",
    "with open(output_code_file, 'w') as f:\n",
    "    f.write(\"# Normalization parameters for feature scaling\\n\")\n",
    "    f.write(\"# Generated from UCI HAR dataset training data\\n\")\n",
    "    f.write(\"# Units: accelerometer in g's, gyroscope in rad/s\\n\\n\")\n",
    "    f.write(\"NORMALIZATION_PARAMS = {\\n\")\n",
    "    for feature_name, params in normalization_params.items():\n",
    "        f.write(f\"    '{feature_name}': {{'min': {params['min']}, 'max': {params['max']}}},\\n\")\n",
    "    f.write(\"}\\n\\n\")\n",
    "    f.write(\"def normalize_feature(value, feature_name):\\n\")\n",
    "    f.write(\"    \\\"\\\"\\\"Normalize a feature value to [-1, 1] range\\n\")\n",
    "    f.write(\"    \\n\")\n",
    "    f.write(\"    Args:\\n\")\n",
    "    f.write(\"        value: Raw feature value (in g's for acceleration, rad/s for gyroscope)\\n\")\n",
    "    f.write(\"        feature_name: Name of the feature (e.g., 'tBodyAcc-mean()-X')\\n\")\n",
    "    f.write(\"    \\n\")\n",
    "    f.write(\"    Returns:\\n\")\n",
    "    f.write(\"        Normalized value in range [-1, 1]\\n\")\n",
    "    f.write(\"    \\\"\\\"\\\"\\n\")\n",
    "    f.write(\"    params = NORMALIZATION_PARAMS.get(feature_name)\\n\")\n",
    "    f.write(\"    if params is None:\\n\")\n",
    "    f.write(\"        raise ValueError(f'Feature {feature_name} not found in normalization parameters')\\n\")\n",
    "    f.write(\"    \\n\")\n",
    "    f.write(\"    min_val = params['min']\\n\")\n",
    "    f.write(\"    max_val = params['max']\\n\")\n",
    "    f.write(\"    \\n\")\n",
    "    f.write(\"    # Avoid division by zero\\n\")\n",
    "    f.write(\"    if abs(max_val - min_val) < 1e-10:\\n\")\n",
    "    f.write(\"        return 0.0\\n\")\n",
    "    f.write(\"    \\n\")\n",
    "    f.write(\"    # Normalize to [-1, 1]\\n\")\n",
    "    f.write(\"    return 2 * (value - min_val) / (max_val - min_val) - 1\\n\")\n",
    "\n",
    "print(f\"\\nNormalization code saved to {output_code_file}\")\n",
    "print(\"\\nUsage in main.py:\")\n",
    "print(\"  from normalization_params import normalize_feature, NORMALIZATION_PARAMS\")\n",
    "print(\"  normalized_value = normalize_feature(raw_value, 'tBodyAcc-mean()-X')\")\n",
    "print(\"\\nIMPORTANT: Make sure to convert accelerometer from m/s² to g's first!\")\n",
    "print(\"  acceleration_g = acceleration_ms2 / 9.80665\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9c2e04",
   "metadata": {},
   "source": [
    "## Filter to Desired Features Only\n",
    "\n",
    "Load `features_DESIRED.txt` which contains the column numbers and names for features we want to keep from the original dataset. Any columns not in this file will be discarded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "654637b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading desired features from features_DESIRED.txt...\n",
      "Number of desired features: 87\n",
      "Feature indices range: 0 to 545\n",
      "\n",
      "Filtered recreated dataset shape: (7352, 87)\n",
      "Expected shape: (7352, 87)\n"
     ]
    }
   ],
   "source": [
    "# Load the desired features list\n",
    "print(\"Loading desired features from features_DESIRED.txt...\")\n",
    "desired_features = []\n",
    "desired_indices = []\n",
    "\n",
    "with open('dataset/features_DESIRED.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        parts = line.strip().split(maxsplit=1)\n",
    "        if len(parts) >= 2:\n",
    "            col_num = int(parts[0])\n",
    "            feature_name = parts[1]\n",
    "            desired_features.append(feature_name)\n",
    "            desired_indices.append(col_num - 1)  # Convert to 0-based index\n",
    "\n",
    "print(f\"Number of desired features: {len(desired_features)}\")\n",
    "print(f\"Feature indices range: {min(desired_indices)} to {max(desired_indices)}\")\n",
    "\n",
    "# Filter the recreated dataset to only include desired features\n",
    "X_train_recreated_filtered = X_train_recreated[:, desired_indices]\n",
    "\n",
    "print(f\"\\nFiltered recreated dataset shape: {X_train_recreated_filtered.shape}\")\n",
    "print(f\"Expected shape: ({X_train_recreated.shape[0]}, {len(desired_features)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eab5a40",
   "metadata": {},
   "source": [
    "## Save Filtered Dataset\n",
    "\n",
    "Save both the full dataset and the filtered dataset with only desired features. The filtered dataset is saved as CSV with column headers from `features_DESIRED.txt`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6e056f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full recreated dataset (561 features) saved to X_train_recreated_full.txt\n",
      "Filtered recreated dataset (87 features) saved to X_train_recreated_filtered.csv\n",
      "Filtered recreated dataset (87 features) saved to X_train_recreated_filtered.csv\n",
      "Filtered recreated dataset (87 features) also saved to X_train_recreated_filtered.txt (TXT format)\n",
      "\n",
      "First 5 rows of CSV (first 5 columns):\n",
      "   tBodyAcc-mean()-X  tBodyAcc-mean()-Y  tBodyAcc-mean()-Z  tBodyAcc-max()-X  \\\n",
      "0           0.288585          -0.020294          -0.132905         -0.934724   \n",
      "1           0.278419          -0.016411          -0.123520         -0.943068   \n",
      "2           0.279653          -0.019467          -0.113462         -0.938692   \n",
      "3           0.279174          -0.026201          -0.123283         -0.938692   \n",
      "4           0.276629          -0.016570          -0.115362         -0.942469   \n",
      "\n",
      "   tBodyAcc-max()-Y  tBodyAcc-max()-Z  tBodyAcc-min()-X  tBodyAcc-min()-Y  \\\n",
      "0         -0.567378         -0.744413          0.852947          0.685845   \n",
      "1         -0.557851         -0.818409          0.849308          0.685845   \n",
      "2         -0.557851         -0.818409          0.843609          0.682401   \n",
      "3         -0.576159         -0.829711          0.843609          0.682401   \n",
      "4         -0.569174         -0.824705          0.849095          0.683250   \n",
      "\n",
      "   tBodyAcc-min()-Z  tBodyAccJerk-mean()-X  ...  fBodyAccMag-min()  \\\n",
      "0          0.814263               0.059653  ...          -0.926329   \n",
      "1          0.822637               0.057089  ...          -0.987112   \n",
      "2          0.839344               0.057929  ...          -0.990018   \n",
      "3          0.837869               0.059873  ...          -0.998312   \n",
      "4          0.837869               0.056635  ...          -0.988001   \n",
      "\n",
      "   fBodyBodyAccJerkMag-mean()  fBodyBodyAccJerkMag-max()  \\\n",
      "0                   -0.993293                  -0.993179   \n",
      "1                   -0.990654                  -0.991163   \n",
      "2                   -0.988493                  -0.988313   \n",
      "3                   -0.992520                  -0.992876   \n",
      "4                   -0.995071                  -0.993297   \n",
      "\n",
      "   fBodyBodyAccJerkMag-min()  fBodyBodyGyroMag-mean()  fBodyBodyGyroMag-max()  \\\n",
      "0                  -0.986691                -0.975030               -0.968959   \n",
      "1                  -0.995790                -0.984924               -0.980683   \n",
      "2                  -0.992879                -0.984160               -0.976317   \n",
      "3                  -0.991808                -0.986246               -0.982060   \n",
      "4                  -0.993331                -0.988761               -0.985204   \n",
      "\n",
      "   fBodyBodyGyroMag-min()  fBodyBodyGyroJerkMag-mean()  \\\n",
      "0               -0.989569                    -0.992583   \n",
      "1               -0.991900                    -0.995682   \n",
      "2               -0.995774                    -0.994817   \n",
      "3               -0.996271                    -0.995425   \n",
      "4               -0.998425                    -0.995247   \n",
      "\n",
      "   fBodyBodyGyroJerkMag-max()  fBodyBodyGyroJerkMag-min()  \n",
      "0                   -0.994241                   -0.991644  \n",
      "1                   -0.995115                   -0.993414  \n",
      "2                   -0.993354                   -0.995252  \n",
      "3                   -0.995517                   -0.988532  \n",
      "4                   -0.995840                   -0.995152  \n",
      "\n",
      "[5 rows x 87 columns]\n",
      "Filtered recreated dataset (87 features) also saved to X_train_recreated_filtered.txt (TXT format)\n",
      "\n",
      "First 5 rows of CSV (first 5 columns):\n",
      "   tBodyAcc-mean()-X  tBodyAcc-mean()-Y  tBodyAcc-mean()-Z  tBodyAcc-max()-X  \\\n",
      "0           0.288585          -0.020294          -0.132905         -0.934724   \n",
      "1           0.278419          -0.016411          -0.123520         -0.943068   \n",
      "2           0.279653          -0.019467          -0.113462         -0.938692   \n",
      "3           0.279174          -0.026201          -0.123283         -0.938692   \n",
      "4           0.276629          -0.016570          -0.115362         -0.942469   \n",
      "\n",
      "   tBodyAcc-max()-Y  tBodyAcc-max()-Z  tBodyAcc-min()-X  tBodyAcc-min()-Y  \\\n",
      "0         -0.567378         -0.744413          0.852947          0.685845   \n",
      "1         -0.557851         -0.818409          0.849308          0.685845   \n",
      "2         -0.557851         -0.818409          0.843609          0.682401   \n",
      "3         -0.576159         -0.829711          0.843609          0.682401   \n",
      "4         -0.569174         -0.824705          0.849095          0.683250   \n",
      "\n",
      "   tBodyAcc-min()-Z  tBodyAccJerk-mean()-X  ...  fBodyAccMag-min()  \\\n",
      "0          0.814263               0.059653  ...          -0.926329   \n",
      "1          0.822637               0.057089  ...          -0.987112   \n",
      "2          0.839344               0.057929  ...          -0.990018   \n",
      "3          0.837869               0.059873  ...          -0.998312   \n",
      "4          0.837869               0.056635  ...          -0.988001   \n",
      "\n",
      "   fBodyBodyAccJerkMag-mean()  fBodyBodyAccJerkMag-max()  \\\n",
      "0                   -0.993293                  -0.993179   \n",
      "1                   -0.990654                  -0.991163   \n",
      "2                   -0.988493                  -0.988313   \n",
      "3                   -0.992520                  -0.992876   \n",
      "4                   -0.995071                  -0.993297   \n",
      "\n",
      "   fBodyBodyAccJerkMag-min()  fBodyBodyGyroMag-mean()  fBodyBodyGyroMag-max()  \\\n",
      "0                  -0.986691                -0.975030               -0.968959   \n",
      "1                  -0.995790                -0.984924               -0.980683   \n",
      "2                  -0.992879                -0.984160               -0.976317   \n",
      "3                  -0.991808                -0.986246               -0.982060   \n",
      "4                  -0.993331                -0.988761               -0.985204   \n",
      "\n",
      "   fBodyBodyGyroMag-min()  fBodyBodyGyroJerkMag-mean()  \\\n",
      "0               -0.989569                    -0.992583   \n",
      "1               -0.991900                    -0.995682   \n",
      "2               -0.995774                    -0.994817   \n",
      "3               -0.996271                    -0.995425   \n",
      "4               -0.998425                    -0.995247   \n",
      "\n",
      "   fBodyBodyGyroJerkMag-max()  fBodyBodyGyroJerkMag-min()  \n",
      "0                   -0.994241                   -0.991644  \n",
      "1                   -0.995115                   -0.993414  \n",
      "2                   -0.993354                   -0.995252  \n",
      "3                   -0.995517                   -0.988532  \n",
      "4                   -0.995840                   -0.995152  \n",
      "\n",
      "[5 rows x 87 columns]\n"
     ]
    }
   ],
   "source": [
    "# Save the full recreated dataset (all 561 features)\n",
    "output_file_full = 'X_train_recreated_full.txt'\n",
    "try:\n",
    "    np.savetxt(output_file_full, X_train_recreated, fmt='%.16f')\n",
    "    print(f\"Full recreated dataset (561 features) saved to {output_file_full}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving full dataset: {e}\")\n",
    "    # Try with explicit path\n",
    "    import os\n",
    "    output_file_full = os.path.join(os.getcwd(), 'X_train_recreated_full.txt')\n",
    "    np.savetxt(output_file_full, X_train_recreated, fmt='%.16f')\n",
    "    print(f\"Full recreated dataset (561 features) saved to {output_file_full}\")\n",
    "\n",
    "# Save the filtered dataset as CSV with headers\n",
    "output_file_csv = 'X_train_recreated_filtered.csv'\n",
    "\n",
    "# Create DataFrame with feature names as column headers\n",
    "df_filtered = pd.DataFrame(X_train_recreated_filtered, columns=desired_features)\n",
    "\n",
    "# Save to CSV\n",
    "df_filtered.to_csv(output_file_csv, index=False)\n",
    "print(f\"Filtered recreated dataset ({len(desired_features)} features) saved to {output_file_csv}\")\n",
    "\n",
    "# Also save as TXT for backward compatibility (optional)\n",
    "output_file_filtered = 'X_train_recreated_filtered.txt'\n",
    "np.savetxt(output_file_filtered, X_train_recreated_filtered, fmt='%.16f')\n",
    "print(f\"Filtered recreated dataset ({len(desired_features)} features) also saved to {output_file_filtered} (TXT format)\")\n",
    "\n",
    "# Display first few rows\n",
    "print(f\"\\nFirst 5 rows of CSV (first 5 columns):\")\n",
    "print(df_filtered.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd9e421",
   "metadata": {},
   "source": [
    "## Verification - Compare Desired Features Only\n",
    "\n",
    "Compare the filtered recreated dataset with the original dataset, focusing only on the desired features. This will provide better correlation statistics since we're comparing only the features that matter most."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7e3e1358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading original X_train.txt...\n",
      "Original dataset shape: (7352, 561)\n",
      "Filtered original dataset shape: (7352, 87)\n",
      "Filtered recreated dataset shape: (7352, 87)\n",
      "✓ Shapes match!\n",
      "\n",
      "============================================================\n",
      "COMPARISON: DESIRED FEATURES ONLY (87 features)\n",
      "============================================================\n",
      "\n",
      "Mean correlation across desired features: 0.9645\n",
      "Median correlation: 0.9989\n",
      "Features with correlation > 0.9: 81/87\n",
      "Features with correlation > 0.95: 70/87\n",
      "Features with correlation > 0.99: 61/87\n",
      "Features with correlation > 0.999: 43/87\n",
      "\n",
      "Features with correlation < 0.9: 6\n",
      "Low-correlation desired features:\n",
      "  Feature 357 (fBodyAccJerk-min()-X): correlation = 0.5993\n",
      "  Feature 358 (fBodyAccJerk-min()-Y): correlation = 0.5778\n",
      "  Feature 359 (fBodyAccJerk-min()-Z): correlation = 0.5889\n",
      "  Feature 433 (fBodyGyro-max()-X): correlation = 0.8193\n",
      "  Feature 520 (fBodyBodyAccJerkMag-min()): correlation = 0.6619\n",
      "  Feature 546 (fBodyBodyGyroJerkMag-min()): correlation = 0.6974\n",
      "\n",
      "Mean Absolute Error (desired features): 0.030257\n",
      "Root Mean Square Error (desired features): 0.090585\n",
      "\n",
      "Sample comparison (first 3 windows, first 5 desired features):\n",
      "Original:\n",
      "[[ 0.28858451 -0.02029417 -0.13290514 -0.93472378 -0.56737807]\n",
      " [ 0.27841883 -0.01641057 -0.12352019 -0.94306751 -0.55785126]\n",
      " [ 0.27965306 -0.01946716 -0.11346169 -0.93869155 -0.55785126]]\n",
      "\n",
      "Recreated:\n",
      "[[ 0.2885845  -0.02029417 -0.13290515 -0.9347238  -0.56737806]\n",
      " [ 0.27841882 -0.01641057 -0.12352019 -0.94306754 -0.55785125]\n",
      " [ 0.27965306 -0.01946715 -0.1134617  -0.93869157 -0.55785125]]\n",
      "\n",
      "Difference:\n",
      "[[ 5.96865318e-09 -2.89710791e-09  6.15705051e-09  2.41814231e-08\n",
      "  -1.15158791e-08]\n",
      " [ 6.14044338e-09 -2.77959648e-09  5.75970188e-10  2.57718554e-08\n",
      "  -1.13388835e-08]\n",
      " [ 3.07520920e-09 -2.71563823e-09  7.98316274e-09  2.19757400e-08\n",
      "  -1.13388835e-08]]\n",
      "\n",
      "============================================================\n",
      "SUMMARY\n",
      "============================================================\n",
      "Total desired features: 87\n",
      "Perfect matches (>0.999): 43\n",
      "Excellent matches (>0.99): 61\n",
      "Good matches (>0.95): 70\n",
      "Acceptable matches (>0.9): 81\n",
      "Poor matches (<0.9): 6\n",
      "\n",
      "Success rate (correlation > 0.9): 93.1%\n",
      "Original dataset shape: (7352, 561)\n",
      "Filtered original dataset shape: (7352, 87)\n",
      "Filtered recreated dataset shape: (7352, 87)\n",
      "✓ Shapes match!\n",
      "\n",
      "============================================================\n",
      "COMPARISON: DESIRED FEATURES ONLY (87 features)\n",
      "============================================================\n",
      "\n",
      "Mean correlation across desired features: 0.9645\n",
      "Median correlation: 0.9989\n",
      "Features with correlation > 0.9: 81/87\n",
      "Features with correlation > 0.95: 70/87\n",
      "Features with correlation > 0.99: 61/87\n",
      "Features with correlation > 0.999: 43/87\n",
      "\n",
      "Features with correlation < 0.9: 6\n",
      "Low-correlation desired features:\n",
      "  Feature 357 (fBodyAccJerk-min()-X): correlation = 0.5993\n",
      "  Feature 358 (fBodyAccJerk-min()-Y): correlation = 0.5778\n",
      "  Feature 359 (fBodyAccJerk-min()-Z): correlation = 0.5889\n",
      "  Feature 433 (fBodyGyro-max()-X): correlation = 0.8193\n",
      "  Feature 520 (fBodyBodyAccJerkMag-min()): correlation = 0.6619\n",
      "  Feature 546 (fBodyBodyGyroJerkMag-min()): correlation = 0.6974\n",
      "\n",
      "Mean Absolute Error (desired features): 0.030257\n",
      "Root Mean Square Error (desired features): 0.090585\n",
      "\n",
      "Sample comparison (first 3 windows, first 5 desired features):\n",
      "Original:\n",
      "[[ 0.28858451 -0.02029417 -0.13290514 -0.93472378 -0.56737807]\n",
      " [ 0.27841883 -0.01641057 -0.12352019 -0.94306751 -0.55785126]\n",
      " [ 0.27965306 -0.01946716 -0.11346169 -0.93869155 -0.55785126]]\n",
      "\n",
      "Recreated:\n",
      "[[ 0.2885845  -0.02029417 -0.13290515 -0.9347238  -0.56737806]\n",
      " [ 0.27841882 -0.01641057 -0.12352019 -0.94306754 -0.55785125]\n",
      " [ 0.27965306 -0.01946715 -0.1134617  -0.93869157 -0.55785125]]\n",
      "\n",
      "Difference:\n",
      "[[ 5.96865318e-09 -2.89710791e-09  6.15705051e-09  2.41814231e-08\n",
      "  -1.15158791e-08]\n",
      " [ 6.14044338e-09 -2.77959648e-09  5.75970188e-10  2.57718554e-08\n",
      "  -1.13388835e-08]\n",
      " [ 3.07520920e-09 -2.71563823e-09  7.98316274e-09  2.19757400e-08\n",
      "  -1.13388835e-08]]\n",
      "\n",
      "============================================================\n",
      "SUMMARY\n",
      "============================================================\n",
      "Total desired features: 87\n",
      "Perfect matches (>0.999): 43\n",
      "Excellent matches (>0.99): 61\n",
      "Good matches (>0.95): 70\n",
      "Acceptable matches (>0.9): 81\n",
      "Poor matches (<0.9): 6\n",
      "\n",
      "Success rate (correlation > 0.9): 93.1%\n"
     ]
    }
   ],
   "source": [
    "# Load original X_train.txt and filter to desired features\n",
    "print(\"Loading original X_train.txt...\")\n",
    "try:\n",
    "    X_train_original = np.loadtxt('dataset/train/X_train.txt')\n",
    "    print(f\"Original dataset shape: {X_train_original.shape}\")\n",
    "    \n",
    "    # Filter original dataset to only include desired features\n",
    "    X_train_original_filtered = X_train_original[:, desired_indices]\n",
    "    print(f\"Filtered original dataset shape: {X_train_original_filtered.shape}\")\n",
    "    print(f\"Filtered recreated dataset shape: {X_train_recreated_filtered.shape}\")\n",
    "    \n",
    "    # Compare shapes\n",
    "    if X_train_original_filtered.shape == X_train_recreated_filtered.shape:\n",
    "        print(\"✓ Shapes match!\")\n",
    "    else:\n",
    "        print(\"✗ Shapes do not match!\")\n",
    "    \n",
    "    # Calculate correlation for each desired feature\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"COMPARISON: DESIRED FEATURES ONLY ({} features)\".format(len(desired_features)))\n",
    "    print('='*60)\n",
    "    \n",
    "    correlations_filtered = []\n",
    "    for i in range(X_train_original_filtered.shape[1]):\n",
    "        corr = np.corrcoef(X_train_original_filtered[:, i], X_train_recreated_filtered[:, i])[0, 1]\n",
    "        correlations_filtered.append(corr)\n",
    "    \n",
    "    correlations_filtered = np.array(correlations_filtered)\n",
    "    print(f\"\\nMean correlation across desired features: {np.nanmean(correlations_filtered):.4f}\")\n",
    "    print(f\"Median correlation: {np.nanmedian(correlations_filtered):.4f}\")\n",
    "    print(f\"Features with correlation > 0.9: {np.sum(correlations_filtered > 0.9)}/{len(correlations_filtered)}\")\n",
    "    print(f\"Features with correlation > 0.95: {np.sum(correlations_filtered > 0.95)}/{len(correlations_filtered)}\")\n",
    "    print(f\"Features with correlation > 0.99: {np.sum(correlations_filtered > 0.99)}/{len(correlations_filtered)}\")\n",
    "    print(f\"Features with correlation > 0.999: {np.sum(correlations_filtered > 0.999)}/{len(correlations_filtered)}\")\n",
    "    \n",
    "    # Find features with low correlation\n",
    "    low_corr_features_filtered = np.where(correlations_filtered < 0.9)[0]\n",
    "    if len(low_corr_features_filtered) > 0:\n",
    "        print(f\"\\nFeatures with correlation < 0.9: {len(low_corr_features_filtered)}\")\n",
    "        print(\"Low-correlation desired features:\")\n",
    "        for idx in low_corr_features_filtered:\n",
    "            orig_idx = desired_indices[idx]\n",
    "            print(f\"  Feature {orig_idx+1} ({desired_features[idx]}): correlation = {correlations_filtered[idx]:.4f}\")\n",
    "    else:\n",
    "        print(\"\\n✓ All desired features have correlation ≥ 0.9!\")\n",
    "    \n",
    "    # Calculate mean absolute error\n",
    "    mae_filtered = np.mean(np.abs(X_train_original_filtered - X_train_recreated_filtered))\n",
    "    print(f\"\\nMean Absolute Error (desired features): {mae_filtered:.6f}\")\n",
    "    \n",
    "    # Calculate RMSE\n",
    "    rmse_filtered = np.sqrt(np.mean((X_train_original_filtered - X_train_recreated_filtered)**2))\n",
    "    print(f\"Root Mean Square Error (desired features): {rmse_filtered:.6f}\")\n",
    "    \n",
    "    # Show comparison for first few samples\n",
    "    print(\"\\nSample comparison (first 3 windows, first 5 desired features):\")\n",
    "    print(\"Original:\")\n",
    "    print(X_train_original_filtered[:3, :5])\n",
    "    print(\"\\nRecreated:\")\n",
    "    print(X_train_recreated_filtered[:3, :5])\n",
    "    print(\"\\nDifference:\")\n",
    "    print(X_train_original_filtered[:3, :5] - X_train_recreated_filtered[:3, :5])\n",
    "    \n",
    "    # Summary statistics\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"SUMMARY\")\n",
    "    print('='*60)\n",
    "    print(f\"Total desired features: {len(desired_features)}\")\n",
    "    print(f\"Perfect matches (>0.999): {np.sum(correlations_filtered > 0.999)}\")\n",
    "    print(f\"Excellent matches (>0.99): {np.sum(correlations_filtered > 0.99)}\")\n",
    "    print(f\"Good matches (>0.95): {np.sum(correlations_filtered > 0.95)}\")\n",
    "    print(f\"Acceptable matches (>0.9): {np.sum(correlations_filtered > 0.9)}\")\n",
    "    print(f\"Poor matches (<0.9): {len(low_corr_features_filtered)}\")\n",
    "    \n",
    "    success_rate = np.sum(correlations_filtered > 0.9) / len(correlations_filtered) * 100\n",
    "    print(f\"\\nSuccess rate (correlation > 0.9): {success_rate:.1f}%\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"Error: dataset/train/X_train.txt not found\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading original dataset: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd24725",
   "metadata": {},
   "source": [
    "## Save Recreated Dataset\n",
    "\n",
    "Save the recreated feature vectors to a text file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9aad37eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recreated dataset saved to X_train_recreated.txt\n",
      "\n",
      "First 5 rows, first 10 features:\n",
      "[[ 0.2885845  -0.02029417 -0.13290515 -0.9952786  -0.98250382 -0.91352645\n",
      "  -0.99511208 -0.98290823 -0.92352702 -0.9347238 ]\n",
      " [ 0.27841882 -0.01641057 -0.12352019 -0.99824528 -0.97435149 -0.96032199\n",
      "  -0.99880719 -0.97450212 -0.95768622 -0.94306754]\n",
      " [ 0.27965306 -0.01946715 -0.1134617  -0.99537956 -0.96588307 -0.97894396\n",
      "  -0.99651994 -0.96307131 -0.97746859 -0.93869157]\n",
      " [ 0.27917393 -0.02620064 -0.12328257 -0.99609149 -0.9828087  -0.9906751\n",
      "  -0.99709947 -0.98246636 -0.9893025  -0.93869157]\n",
      " [ 0.27662876 -0.01656965 -0.11536186 -0.99813862 -0.98011008 -0.99048163\n",
      "  -0.99832113 -0.9793378  -0.99044113 -0.94246914]]\n"
     ]
    }
   ],
   "source": [
    "# Save to file\n",
    "output_file = 'X_train_recreated.txt'\n",
    "np.savetxt(output_file, X_train_recreated, fmt='%.16f')\n",
    "print(f\"Recreated dataset saved to {output_file}\")\n",
    "\n",
    "# Display first few rows and columns\n",
    "print(\"\\nFirst 5 rows, first 10 features:\")\n",
    "print(X_train_recreated[:5, :10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f6fc2c",
   "metadata": {},
   "source": [
    "## Verification (Optional)\n",
    "\n",
    "Compare a few samples with the original dataset to verify correctness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3f6635a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading original X_train.txt...\n",
      "Original dataset shape: (7352, 561)\n",
      "Recreated dataset shape: (7352, 561)\n",
      "✓ Shapes match!\n",
      "\n",
      "Calculating feature-wise correlations...\n",
      "Mean correlation across all features: 0.6234\n",
      "Median correlation: 0.9303\n",
      "Features with correlation > 0.9: 289/561\n",
      "Features with correlation > 0.95: 257/561\n",
      "Features with correlation > 0.99: 195/561\n",
      "\n",
      "Features with correlation < 0.8: 236\n",
      "First 10 low-correlation features:\n",
      "  Feature 23 (tBodyAcc-entropy()-X): correlation = 0.2589\n",
      "  Feature 24 (tBodyAcc-entropy()-Y): correlation = -0.0258\n",
      "  Feature 25 (tBodyAcc-entropy()-Z): correlation = -0.0642\n",
      "  Feature 26 (tBodyAcc-arCoeff()-X,1): correlation = -0.7167\n",
      "  Feature 27 (tBodyAcc-arCoeff()-X,2): correlation = 0.2997\n",
      "  Feature 28 (tBodyAcc-arCoeff()-X,3): correlation = -0.2317\n",
      "  Feature 29 (tBodyAcc-arCoeff()-X,4): correlation = -0.1230\n",
      "  Feature 30 (tBodyAcc-arCoeff()-Y,1): correlation = -0.4860\n",
      "  Feature 31 (tBodyAcc-arCoeff()-Y,2): correlation = -0.0062\n",
      "  Feature 32 (tBodyAcc-arCoeff()-Y,3): correlation = -0.0563\n",
      "\n",
      "Mean Absolute Error: 0.202425\n",
      "Root Mean Square Error: 0.422903\n",
      "\n",
      "Sample comparison (first 3 windows, first 5 features):\n",
      "Original:\n",
      "[[ 0.28858451 -0.02029417 -0.13290514 -0.9952786  -0.98311061]\n",
      " [ 0.27841883 -0.01641057 -0.12352019 -0.99824528 -0.97530022]\n",
      " [ 0.27965306 -0.01946716 -0.11346169 -0.99537956 -0.96718701]]\n",
      "\n",
      "Recreated:\n",
      "[[ 0.2885845  -0.02029417 -0.13290515 -0.9952786  -0.98250382]\n",
      " [ 0.27841882 -0.01641057 -0.12352019 -0.99824528 -0.97435149]\n",
      " [ 0.27965306 -0.01946715 -0.1134617  -0.99537956 -0.96588307]]\n",
      "\n",
      "Difference:\n",
      "[[ 5.96865318e-09 -2.89710791e-09  6.15705051e-09 -3.08582193e-09\n",
      "  -6.06790297e-04]\n",
      " [ 6.14044338e-09 -2.77959648e-09  5.75970188e-10  2.44922171e-09\n",
      "  -9.48732736e-04]\n",
      " [ 3.07520920e-09 -2.71563823e-09  7.98316274e-09 -2.08308937e-09\n",
      "  -1.30394249e-03]]\n",
      "Original dataset shape: (7352, 561)\n",
      "Recreated dataset shape: (7352, 561)\n",
      "✓ Shapes match!\n",
      "\n",
      "Calculating feature-wise correlations...\n",
      "Mean correlation across all features: 0.6234\n",
      "Median correlation: 0.9303\n",
      "Features with correlation > 0.9: 289/561\n",
      "Features with correlation > 0.95: 257/561\n",
      "Features with correlation > 0.99: 195/561\n",
      "\n",
      "Features with correlation < 0.8: 236\n",
      "First 10 low-correlation features:\n",
      "  Feature 23 (tBodyAcc-entropy()-X): correlation = 0.2589\n",
      "  Feature 24 (tBodyAcc-entropy()-Y): correlation = -0.0258\n",
      "  Feature 25 (tBodyAcc-entropy()-Z): correlation = -0.0642\n",
      "  Feature 26 (tBodyAcc-arCoeff()-X,1): correlation = -0.7167\n",
      "  Feature 27 (tBodyAcc-arCoeff()-X,2): correlation = 0.2997\n",
      "  Feature 28 (tBodyAcc-arCoeff()-X,3): correlation = -0.2317\n",
      "  Feature 29 (tBodyAcc-arCoeff()-X,4): correlation = -0.1230\n",
      "  Feature 30 (tBodyAcc-arCoeff()-Y,1): correlation = -0.4860\n",
      "  Feature 31 (tBodyAcc-arCoeff()-Y,2): correlation = -0.0062\n",
      "  Feature 32 (tBodyAcc-arCoeff()-Y,3): correlation = -0.0563\n",
      "\n",
      "Mean Absolute Error: 0.202425\n",
      "Root Mean Square Error: 0.422903\n",
      "\n",
      "Sample comparison (first 3 windows, first 5 features):\n",
      "Original:\n",
      "[[ 0.28858451 -0.02029417 -0.13290514 -0.9952786  -0.98311061]\n",
      " [ 0.27841883 -0.01641057 -0.12352019 -0.99824528 -0.97530022]\n",
      " [ 0.27965306 -0.01946716 -0.11346169 -0.99537956 -0.96718701]]\n",
      "\n",
      "Recreated:\n",
      "[[ 0.2885845  -0.02029417 -0.13290515 -0.9952786  -0.98250382]\n",
      " [ 0.27841882 -0.01641057 -0.12352019 -0.99824528 -0.97435149]\n",
      " [ 0.27965306 -0.01946715 -0.1134617  -0.99537956 -0.96588307]]\n",
      "\n",
      "Difference:\n",
      "[[ 5.96865318e-09 -2.89710791e-09  6.15705051e-09 -3.08582193e-09\n",
      "  -6.06790297e-04]\n",
      " [ 6.14044338e-09 -2.77959648e-09  5.75970188e-10  2.44922171e-09\n",
      "  -9.48732736e-04]\n",
      " [ 3.07520920e-09 -2.71563823e-09  7.98316274e-09 -2.08308937e-09\n",
      "  -1.30394249e-03]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading original X_train.txt...\n",
      "Original dataset shape: (7352, 561)\n",
      "Recreated dataset shape: (7352, 561)\n",
      "✓ Shapes match!\n",
      "\n",
      "Calculating feature-wise correlations...\n",
      "Mean correlation across all features: 0.6234\n",
      "Median correlation: 0.9303\n",
      "Features with correlation > 0.9: 289/561\n",
      "Features with correlation > 0.95: 257/561\n",
      "Features with correlation > 0.99: 195/561\n",
      "\n",
      "Features with correlation < 0.8: 236\n",
      "First 10 low-correlation features:\n",
      "  Feature 23 (tBodyAcc-entropy()-X): correlation = 0.2589\n",
      "  Feature 24 (tBodyAcc-entropy()-Y): correlation = -0.0258\n",
      "  Feature 25 (tBodyAcc-entropy()-Z): correlation = -0.0642\n",
      "  Feature 26 (tBodyAcc-arCoeff()-X,1): correlation = -0.7167\n",
      "  Feature 27 (tBodyAcc-arCoeff()-X,2): correlation = 0.2997\n",
      "  Feature 28 (tBodyAcc-arCoeff()-X,3): correlation = -0.2317\n",
      "  Feature 29 (tBodyAcc-arCoeff()-X,4): correlation = -0.1230\n",
      "  Feature 30 (tBodyAcc-arCoeff()-Y,1): correlation = -0.4860\n",
      "  Feature 31 (tBodyAcc-arCoeff()-Y,2): correlation = -0.0062\n",
      "  Feature 32 (tBodyAcc-arCoeff()-Y,3): correlation = -0.0563\n",
      "\n",
      "Mean Absolute Error: 0.202425\n",
      "Root Mean Square Error: 0.422903\n",
      "\n",
      "Sample comparison (first 3 windows, first 5 features):\n",
      "Original:\n",
      "[[ 0.28858451 -0.02029417 -0.13290514 -0.9952786  -0.98311061]\n",
      " [ 0.27841883 -0.01641057 -0.12352019 -0.99824528 -0.97530022]\n",
      " [ 0.27965306 -0.01946716 -0.11346169 -0.99537956 -0.96718701]]\n",
      "\n",
      "Recreated:\n",
      "[[ 0.2885845  -0.02029417 -0.13290515 -0.9952786  -0.98250382]\n",
      " [ 0.27841882 -0.01641057 -0.12352019 -0.99824528 -0.97435149]\n",
      " [ 0.27965306 -0.01946715 -0.1134617  -0.99537956 -0.96588307]]\n",
      "\n",
      "Difference:\n",
      "[[ 5.96865318e-09 -2.89710791e-09  6.15705051e-09 -3.08582193e-09\n",
      "  -6.06790297e-04]\n",
      " [ 6.14044338e-09 -2.77959648e-09  5.75970188e-10  2.44922171e-09\n",
      "  -9.48732736e-04]\n",
      " [ 3.07520920e-09 -2.71563823e-09  7.98316274e-09 -2.08308937e-09\n",
      "  -1.30394249e-03]]\n",
      "Original dataset shape: (7352, 561)\n",
      "Recreated dataset shape: (7352, 561)\n",
      "✓ Shapes match!\n",
      "\n",
      "Calculating feature-wise correlations...\n",
      "Mean correlation across all features: 0.6234\n",
      "Median correlation: 0.9303\n",
      "Features with correlation > 0.9: 289/561\n",
      "Features with correlation > 0.95: 257/561\n",
      "Features with correlation > 0.99: 195/561\n",
      "\n",
      "Features with correlation < 0.8: 236\n",
      "First 10 low-correlation features:\n",
      "  Feature 23 (tBodyAcc-entropy()-X): correlation = 0.2589\n",
      "  Feature 24 (tBodyAcc-entropy()-Y): correlation = -0.0258\n",
      "  Feature 25 (tBodyAcc-entropy()-Z): correlation = -0.0642\n",
      "  Feature 26 (tBodyAcc-arCoeff()-X,1): correlation = -0.7167\n",
      "  Feature 27 (tBodyAcc-arCoeff()-X,2): correlation = 0.2997\n",
      "  Feature 28 (tBodyAcc-arCoeff()-X,3): correlation = -0.2317\n",
      "  Feature 29 (tBodyAcc-arCoeff()-X,4): correlation = -0.1230\n",
      "  Feature 30 (tBodyAcc-arCoeff()-Y,1): correlation = -0.4860\n",
      "  Feature 31 (tBodyAcc-arCoeff()-Y,2): correlation = -0.0062\n",
      "  Feature 32 (tBodyAcc-arCoeff()-Y,3): correlation = -0.0563\n",
      "\n",
      "Mean Absolute Error: 0.202425\n",
      "Root Mean Square Error: 0.422903\n",
      "\n",
      "Sample comparison (first 3 windows, first 5 features):\n",
      "Original:\n",
      "[[ 0.28858451 -0.02029417 -0.13290514 -0.9952786  -0.98311061]\n",
      " [ 0.27841883 -0.01641057 -0.12352019 -0.99824528 -0.97530022]\n",
      " [ 0.27965306 -0.01946716 -0.11346169 -0.99537956 -0.96718701]]\n",
      "\n",
      "Recreated:\n",
      "[[ 0.2885845  -0.02029417 -0.13290515 -0.9952786  -0.98250382]\n",
      " [ 0.27841882 -0.01641057 -0.12352019 -0.99824528 -0.97435149]\n",
      " [ 0.27965306 -0.01946715 -0.1134617  -0.99537956 -0.96588307]]\n",
      "\n",
      "Difference:\n",
      "[[ 5.96865318e-09 -2.89710791e-09  6.15705051e-09 -3.08582193e-09\n",
      "  -6.06790297e-04]\n",
      " [ 6.14044338e-09 -2.77959648e-09  5.75970188e-10  2.44922171e-09\n",
      "  -9.48732736e-04]\n",
      " [ 3.07520920e-09 -2.71563823e-09  7.98316274e-09 -2.08308937e-09\n",
      "  -1.30394249e-03]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\dev\\EE5127-Project\\.venv\\Lib\\site-packages\\numpy\\lib\\_function_base_impl.py:3065: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\dev\\EE5127-Project\\.venv\\Lib\\site-packages\\numpy\\lib\\_function_base_impl.py:3066: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    }
   ],
   "source": [
    "# Load original X_train.txt for comparison\n",
    "print(\"Loading original X_train.txt...\")\n",
    "try:\n",
    "    # Load in chunks to handle large file\n",
    "    X_train_original = np.loadtxt('dataset/train/X_train.txt')\n",
    "    print(f\"Original dataset shape: {X_train_original.shape}\")\n",
    "    print(f\"Recreated dataset shape: {X_train_recreated.shape}\")\n",
    "    \n",
    "    # Compare shapes\n",
    "    if X_train_original.shape == X_train_recreated.shape:\n",
    "        print(\"✓ Shapes match!\")\n",
    "    else:\n",
    "        print(\"✗ Shapes do not match!\")\n",
    "    \n",
    "    # Calculate correlation for each feature\n",
    "    print(\"\\nCalculating feature-wise correlations...\")\n",
    "    correlations = []\n",
    "    for i in range(min(X_train_original.shape[1], X_train_recreated.shape[1])):\n",
    "        corr = np.corrcoef(X_train_original[:, i], X_train_recreated[:, i])[0, 1]\n",
    "        correlations.append(corr)\n",
    "    \n",
    "    correlations = np.array(correlations)\n",
    "    print(f\"Mean correlation across all features: {np.nanmean(correlations):.4f}\")\n",
    "    print(f\"Median correlation: {np.nanmedian(correlations):.4f}\")\n",
    "    print(f\"Features with correlation > 0.9: {np.sum(correlations > 0.9)}/{len(correlations)}\")\n",
    "    print(f\"Features with correlation > 0.95: {np.sum(correlations > 0.95)}/{len(correlations)}\")\n",
    "    print(f\"Features with correlation > 0.99: {np.sum(correlations > 0.99)}/{len(correlations)}\")\n",
    "    \n",
    "    # Find features with low correlation\n",
    "    low_corr_features = np.where(correlations < 0.8)[0]\n",
    "    if len(low_corr_features) > 0:\n",
    "        print(f\"\\nFeatures with correlation < 0.8: {len(low_corr_features)}\")\n",
    "        print(\"First 10 low-correlation features:\")\n",
    "        for idx in low_corr_features[:10]:\n",
    "            print(f\"  Feature {idx+1} ({feature_names[idx]}): correlation = {correlations[idx]:.4f}\")\n",
    "    \n",
    "    # Calculate mean absolute error\n",
    "    mae = np.mean(np.abs(X_train_original - X_train_recreated))\n",
    "    print(f\"\\nMean Absolute Error: {mae:.6f}\")\n",
    "    \n",
    "    # Calculate RMSE\n",
    "    rmse = np.sqrt(np.mean((X_train_original - X_train_recreated)**2))\n",
    "    print(f\"Root Mean Square Error: {rmse:.6f}\")\n",
    "    \n",
    "    # Show comparison for first few samples\n",
    "    print(\"\\nSample comparison (first 3 windows, first 5 features):\")\n",
    "    print(\"Original:\")\n",
    "    print(X_train_original[:3, :5])\n",
    "    print(\"\\nRecreated:\")\n",
    "    print(X_train_recreated[:3, :5])\n",
    "    print(\"\\nDifference:\")\n",
    "    print(X_train_original[:3, :5] - X_train_recreated[:3, :5])\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"Error: dataset/train/X_train.txt not found\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading original dataset: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ca05a4",
   "metadata": {},
   "source": [
    "## Process Test Dataset\n",
    "\n",
    "Now let's apply the same processing pipeline to the test dataset to create `X_test_recreated_filtered.csv`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bfd196f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading test dataset inertial signals...\n",
      "Test data shape: (2947, 128)\n",
      "Number of test windows: 2947\n",
      "Samples per window: 128\n",
      "Test data shape: (2947, 128)\n",
      "Number of test windows: 2947\n",
      "Samples per window: 128\n"
     ]
    }
   ],
   "source": [
    "# Load test inertial signals\n",
    "print(\"Loading test dataset inertial signals...\")\n",
    "test_data_dir = 'dataset/test/Inertial Signals/'\n",
    "\n",
    "# Load body accelerometer\n",
    "body_acc_x_test = np.loadtxt(test_data_dir + 'body_acc_x_test.txt')\n",
    "body_acc_y_test = np.loadtxt(test_data_dir + 'body_acc_y_test.txt')\n",
    "body_acc_z_test = np.loadtxt(test_data_dir + 'body_acc_z_test.txt')\n",
    "\n",
    "# Load body gyroscope\n",
    "body_gyro_x_test = np.loadtxt(test_data_dir + 'body_gyro_x_test.txt')\n",
    "body_gyro_y_test = np.loadtxt(test_data_dir + 'body_gyro_y_test.txt')\n",
    "body_gyro_z_test = np.loadtxt(test_data_dir + 'body_gyro_z_test.txt')\n",
    "\n",
    "# Load total accelerometer\n",
    "total_acc_x_test = np.loadtxt(test_data_dir + 'total_acc_x_test.txt')\n",
    "total_acc_y_test = np.loadtxt(test_data_dir + 'total_acc_y_test.txt')\n",
    "total_acc_z_test = np.loadtxt(test_data_dir + 'total_acc_z_test.txt')\n",
    "\n",
    "print(f\"Test data shape: {body_acc_x_test.shape}\")\n",
    "print(f\"Number of test windows: {body_acc_x_test.shape[0]}\")\n",
    "print(f\"Samples per window: {body_acc_x_test.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "36fec3bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating gravity acceleration for test data...\n",
      "Test data derived signals calculated\n",
      "Test data derived signals calculated\n"
     ]
    }
   ],
   "source": [
    "# Calculate gravity acceleration for test data\n",
    "print(\"Calculating gravity acceleration for test data...\")\n",
    "gravity_acc_x_test = np.array([apply_gravity_filter(window) for window in total_acc_x_test])\n",
    "gravity_acc_y_test = np.array([apply_gravity_filter(window) for window in total_acc_y_test])\n",
    "gravity_acc_z_test = np.array([apply_gravity_filter(window) for window in total_acc_z_test])\n",
    "\n",
    "# Calculate jerk signals for test data\n",
    "body_acc_jerk_x_test = calculate_jerk(body_acc_x_test)\n",
    "body_acc_jerk_y_test = calculate_jerk(body_acc_y_test)\n",
    "body_acc_jerk_z_test = calculate_jerk(body_acc_z_test)\n",
    "\n",
    "body_gyro_jerk_x_test = calculate_jerk(body_gyro_x_test)\n",
    "body_gyro_jerk_y_test = calculate_jerk(body_gyro_y_test)\n",
    "body_gyro_jerk_z_test = calculate_jerk(body_gyro_z_test)\n",
    "\n",
    "# Calculate magnitudes for test data\n",
    "body_acc_mag_test = calculate_magnitude(body_acc_x_test, body_acc_y_test, body_acc_z_test)\n",
    "gravity_acc_mag_test = calculate_magnitude(gravity_acc_x_test, gravity_acc_y_test, gravity_acc_z_test)\n",
    "body_acc_jerk_mag_test = calculate_magnitude(body_acc_jerk_x_test, body_acc_jerk_y_test, body_acc_jerk_z_test)\n",
    "body_gyro_mag_test = calculate_magnitude(body_gyro_x_test, body_gyro_y_test, body_gyro_z_test)\n",
    "body_gyro_jerk_mag_test = calculate_magnitude(body_gyro_jerk_x_test, body_gyro_jerk_y_test, body_gyro_jerk_z_test)\n",
    "\n",
    "print(\"Test data derived signals calculated\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "784c0dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features from test data...\n",
      "Extracting time domain features...\n",
      "Extracting frequency domain features...\n",
      "Extracting frequency domain features...\n",
      "Total test features extracted: 468 feature types\n",
      "Total test features extracted: 468 feature types\n"
     ]
    }
   ],
   "source": [
    "# Extract features from test data\n",
    "print(\"Extracting features from test data...\")\n",
    "all_features_test = {}\n",
    "\n",
    "# Time domain features\n",
    "print(\"Extracting time domain features...\")\n",
    "all_features_test.update(extract_features_3d(body_acc_x_test, body_acc_y_test, body_acc_z_test, 'tBodyAcc'))\n",
    "all_features_test.update(extract_features_3d(gravity_acc_x_test, gravity_acc_y_test, gravity_acc_z_test, 'tGravityAcc'))\n",
    "all_features_test.update(extract_features_3d(body_acc_jerk_x_test, body_acc_jerk_y_test, body_acc_jerk_z_test, 'tBodyAccJerk'))\n",
    "all_features_test.update(extract_features_3d(body_gyro_x_test, body_gyro_y_test, body_gyro_z_test, 'tBodyGyro'))\n",
    "all_features_test.update(extract_features_3d(body_gyro_jerk_x_test, body_gyro_jerk_y_test, body_gyro_jerk_z_test, 'tBodyGyroJerk'))\n",
    "\n",
    "all_features_test.update(extract_features_magnitude(body_acc_mag_test, 'tBodyAccMag'))\n",
    "all_features_test.update(extract_features_magnitude(gravity_acc_mag_test, 'tGravityAccMag'))\n",
    "all_features_test.update(extract_features_magnitude(body_acc_jerk_mag_test, 'tBodyAccJerkMag'))\n",
    "all_features_test.update(extract_features_magnitude(body_gyro_mag_test, 'tBodyGyroMag'))\n",
    "all_features_test.update(extract_features_magnitude(body_gyro_jerk_mag_test, 'tBodyGyroJerkMag'))\n",
    "\n",
    "# Frequency domain features\n",
    "print(\"Extracting frequency domain features...\")\n",
    "all_features_test.update(extract_fft_features_3d(body_acc_x_test, body_acc_y_test, body_acc_z_test, 'fBodyAcc'))\n",
    "all_features_test.update(extract_fft_features_3d(body_acc_jerk_x_test, body_acc_jerk_y_test, body_acc_jerk_z_test, 'fBodyAccJerk'))\n",
    "all_features_test.update(extract_fft_features_3d(body_gyro_x_test, body_gyro_y_test, body_gyro_z_test, 'fBodyGyro'))\n",
    "\n",
    "all_features_test.update(extract_fft_features_magnitude(body_acc_mag_test, 'fBodyAccMag'))\n",
    "all_features_test.update(extract_fft_features_magnitude(body_acc_jerk_mag_test, 'fBodyBodyAccJerkMag'))\n",
    "all_features_test.update(extract_fft_features_magnitude(body_gyro_mag_test, 'fBodyBodyGyroMag'))\n",
    "all_features_test.update(extract_fft_features_magnitude(body_gyro_jerk_mag_test, 'fBodyBodyGyroJerkMag'))\n",
    "\n",
    "print(f\"Total test features extracted: {len(all_features_test)} feature types\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "87e9d429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating test feature matrix in correct order...\n",
      "Warning: Feature 'fBodyAccJerk-bandsEnergy()-57,64' not found in test data, using zeros\n",
      "Warning: Feature 'fBodyAccJerk-bandsEnergy()-49,64' not found in test data, using zeros\n",
      "Warning: Feature 'fBodyAccJerk-bandsEnergy()-57,64' not found in test data, using zeros\n",
      "Warning: Feature 'fBodyAccJerk-bandsEnergy()-49,64' not found in test data, using zeros\n",
      "Warning: Feature 'fBodyAccJerk-bandsEnergy()-57,64' not found in test data, using zeros\n",
      "Warning: Feature 'fBodyAccJerk-bandsEnergy()-49,64' not found in test data, using zeros\n",
      "Warning: Feature 'fBodyAccMag-maxInds' not found in test data, using zeros\n",
      "Warning: Feature 'fBodyBodyAccJerkMag-maxInds' not found in test data, using zeros\n",
      "Warning: Feature 'fBodyBodyGyroMag-maxInds' not found in test data, using zeros\n",
      "Warning: Feature 'fBodyBodyGyroJerkMag-maxInds' not found in test data, using zeros\n",
      "Warning: Feature 'angle(tBodyAccMean,gravity)' not found in test data, using zeros\n",
      "Warning: Feature 'angle(tBodyAccJerkMean),gravityMean)' not found in test data, using zeros\n",
      "Warning: Feature 'angle(tBodyGyroMean,gravityMean)' not found in test data, using zeros\n",
      "Warning: Feature 'angle(tBodyGyroJerkMean,gravityMean)' not found in test data, using zeros\n",
      "Warning: Feature 'angle(X,gravityMean)' not found in test data, using zeros\n",
      "Warning: Feature 'angle(Y,gravityMean)' not found in test data, using zeros\n",
      "Warning: Feature 'angle(Z,gravityMean)' not found in test data, using zeros\n",
      "Test dataset shape: (2947, 561)\n",
      "Expected shape: (2947, 561)\n"
     ]
    }
   ],
   "source": [
    "# Create feature matrix for test data in correct order\n",
    "print(\"Creating test feature matrix in correct order...\")\n",
    "feature_data_test = []\n",
    "for feature_name in feature_names:\n",
    "    if feature_name in all_features_test:\n",
    "        feature_data_test.append(all_features_test[feature_name])\n",
    "    else:\n",
    "        print(f\"Warning: Feature '{feature_name}' not found in test data, using zeros\")\n",
    "        feature_data_test.append(np.zeros(body_acc_x_test.shape[0]))\n",
    "\n",
    "X_test_recreated = np.array(feature_data_test).T\n",
    "\n",
    "print(f\"Test dataset shape: {X_test_recreated.shape}\")\n",
    "print(f\"Expected shape: ({body_acc_x_test.shape[0]}, 561)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f780cc9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizing test features using training data parameters...\n",
      "Normalized test dataset shape: (2947, 561)\n",
      "Min value: -1.706268\n",
      "Max value: 1.731001\n"
     ]
    }
   ],
   "source": [
    "# Normalize test data using the SAME normalization parameters from training data\n",
    "print(\"Normalizing test features using training data parameters...\")\n",
    "\n",
    "X_test_normalized = np.zeros_like(X_test_recreated)\n",
    "\n",
    "for i in range(X_test_recreated.shape[1]):\n",
    "    feature_values = X_test_recreated[:, i]\n",
    "    \n",
    "    # Use the min/max from TRAINING data (stored in feature_data[i])\n",
    "    training_feature_values = np.array(feature_data[i])\n",
    "    min_val = np.min(training_feature_values)\n",
    "    max_val = np.max(training_feature_values)\n",
    "    \n",
    "    # Avoid division by zero\n",
    "    if max_val - min_val > 1e-10:\n",
    "        # Normalize to [-1, 1] using training parameters\n",
    "        X_test_normalized[:, i] = 2 * (feature_values - min_val) / (max_val - min_val) - 1\n",
    "    else:\n",
    "        # If all training values were the same, set to 0\n",
    "        X_test_normalized[:, i] = 0\n",
    "\n",
    "print(f\"Normalized test dataset shape: {X_test_normalized.shape}\")\n",
    "print(f\"Min value: {np.min(X_test_normalized):.6f}\")\n",
    "print(f\"Max value: {np.max(X_test_normalized):.6f}\")\n",
    "\n",
    "# Update the main variable\n",
    "X_test_recreated = X_test_normalized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "088f8d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering test data to desired features...\n",
      "Filtered test dataset shape: (2947, 87)\n",
      "Expected shape: (2947, 87)\n"
     ]
    }
   ],
   "source": [
    "# Filter test data to only include desired features\n",
    "print(\"Filtering test data to desired features...\")\n",
    "X_test_recreated_filtered = X_test_recreated[:, desired_indices]\n",
    "\n",
    "print(f\"Filtered test dataset shape: {X_test_recreated_filtered.shape}\")\n",
    "print(f\"Expected shape: ({X_test_recreated.shape[0]}, {len(desired_features)})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e5684481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving test dataset...\n",
      "Full test dataset (561 features) saved to X_test_recreated_full.txt\n",
      "Full test dataset (561 features) saved to X_test_recreated_full.txt\n",
      "Filtered test dataset (87 features) saved to X_test_recreated_filtered.csv\n",
      "Filtered test dataset (87 features) also saved to X_test_recreated_filtered.txt (TXT format)\n",
      "\n",
      "First 5 rows of test CSV (first 5 columns):\n",
      "   tBodyAcc-mean()-X  tBodyAcc-mean()-Y  tBodyAcc-mean()-Z  tBodyAcc-max()-X  \\\n",
      "0           0.257178          -0.023285          -0.014654         -0.894088   \n",
      "1           0.286027          -0.013163          -0.119083         -0.894088   \n",
      "2           0.275485          -0.026050          -0.118152         -0.939260   \n",
      "3           0.270298          -0.032614          -0.117520         -0.938610   \n",
      "4           0.274833          -0.027848          -0.129527         -0.938610   \n",
      "\n",
      "   tBodyAcc-max()-Y  tBodyAcc-max()-Z  tBodyAcc-min()-X  tBodyAcc-min()-Y  \\\n",
      "0         -0.554577         -0.466223          0.717208          0.635502   \n",
      "1         -0.554577         -0.806013          0.768031          0.683698   \n",
      "2         -0.568512         -0.799116          0.848305          0.667864   \n",
      "3         -0.568512         -0.799116          0.848305          0.667864   \n",
      "4         -0.560831         -0.825894          0.849179          0.670700   \n",
      "\n",
      "   tBodyAcc-min()-Z  tBodyAccJerk-mean()-X  ...  fBodyAccMag-min()  \\\n",
      "0          0.789497               0.053082  ...          -0.945361   \n",
      "1          0.796706               0.052179  ...          -0.957262   \n",
      "2          0.822442               0.052481  ...          -0.988102   \n",
      "3          0.822442               0.058326  ...          -0.988007   \n",
      "4          0.829897               0.060682  ...          -0.986013   \n",
      "\n",
      "   fBodyBodyAccJerkMag-mean()  fBodyBodyAccJerkMag-max()  \\\n",
      "0                   -0.903062                  -0.929478   \n",
      "1                   -0.952714                  -0.973965   \n",
      "2                   -0.973317                  -0.981355   \n",
      "3                   -0.973201                  -0.982573   \n",
      "4                   -0.986839                  -0.986644   \n",
      "\n",
      "   fBodyBodyAccJerkMag-min()  fBodyBodyGyroMag-mean()  fBodyBodyGyroMag-max()  \\\n",
      "0                  -0.953249                -0.762068               -0.795544   \n",
      "1                  -0.994096                -0.910008               -0.898433   \n",
      "2                  -0.969949                -0.961232               -0.939194   \n",
      "3                  -0.982329                -0.964772               -0.947184   \n",
      "4                  -0.983123                -0.968714               -0.957419   \n",
      "\n",
      "   fBodyBodyGyroMag-min()  fBodyBodyGyroJerkMag-mean()  \\\n",
      "0               -0.938029                    -0.898462   \n",
      "1               -0.978540                    -0.956813   \n",
      "2               -0.997735                    -0.986086   \n",
      "3               -0.996201                    -0.986557   \n",
      "4               -0.993804                    -0.990214   \n",
      "\n",
      "   fBodyBodyGyroJerkMag-max()  fBodyBodyGyroJerkMag-min()  \n",
      "0                   -0.925076                   -0.942807  \n",
      "1                   -0.973749                   -0.963480  \n",
      "2                   -0.986690                   -0.991881  \n",
      "3                   -0.988878                   -0.982714  \n",
      "4                   -0.990152                   -0.993921  \n",
      "\n",
      "[5 rows x 87 columns]\n",
      "Filtered test dataset (87 features) saved to X_test_recreated_filtered.csv\n",
      "Filtered test dataset (87 features) also saved to X_test_recreated_filtered.txt (TXT format)\n",
      "\n",
      "First 5 rows of test CSV (first 5 columns):\n",
      "   tBodyAcc-mean()-X  tBodyAcc-mean()-Y  tBodyAcc-mean()-Z  tBodyAcc-max()-X  \\\n",
      "0           0.257178          -0.023285          -0.014654         -0.894088   \n",
      "1           0.286027          -0.013163          -0.119083         -0.894088   \n",
      "2           0.275485          -0.026050          -0.118152         -0.939260   \n",
      "3           0.270298          -0.032614          -0.117520         -0.938610   \n",
      "4           0.274833          -0.027848          -0.129527         -0.938610   \n",
      "\n",
      "   tBodyAcc-max()-Y  tBodyAcc-max()-Z  tBodyAcc-min()-X  tBodyAcc-min()-Y  \\\n",
      "0         -0.554577         -0.466223          0.717208          0.635502   \n",
      "1         -0.554577         -0.806013          0.768031          0.683698   \n",
      "2         -0.568512         -0.799116          0.848305          0.667864   \n",
      "3         -0.568512         -0.799116          0.848305          0.667864   \n",
      "4         -0.560831         -0.825894          0.849179          0.670700   \n",
      "\n",
      "   tBodyAcc-min()-Z  tBodyAccJerk-mean()-X  ...  fBodyAccMag-min()  \\\n",
      "0          0.789497               0.053082  ...          -0.945361   \n",
      "1          0.796706               0.052179  ...          -0.957262   \n",
      "2          0.822442               0.052481  ...          -0.988102   \n",
      "3          0.822442               0.058326  ...          -0.988007   \n",
      "4          0.829897               0.060682  ...          -0.986013   \n",
      "\n",
      "   fBodyBodyAccJerkMag-mean()  fBodyBodyAccJerkMag-max()  \\\n",
      "0                   -0.903062                  -0.929478   \n",
      "1                   -0.952714                  -0.973965   \n",
      "2                   -0.973317                  -0.981355   \n",
      "3                   -0.973201                  -0.982573   \n",
      "4                   -0.986839                  -0.986644   \n",
      "\n",
      "   fBodyBodyAccJerkMag-min()  fBodyBodyGyroMag-mean()  fBodyBodyGyroMag-max()  \\\n",
      "0                  -0.953249                -0.762068               -0.795544   \n",
      "1                  -0.994096                -0.910008               -0.898433   \n",
      "2                  -0.969949                -0.961232               -0.939194   \n",
      "3                  -0.982329                -0.964772               -0.947184   \n",
      "4                  -0.983123                -0.968714               -0.957419   \n",
      "\n",
      "   fBodyBodyGyroMag-min()  fBodyBodyGyroJerkMag-mean()  \\\n",
      "0               -0.938029                    -0.898462   \n",
      "1               -0.978540                    -0.956813   \n",
      "2               -0.997735                    -0.986086   \n",
      "3               -0.996201                    -0.986557   \n",
      "4               -0.993804                    -0.990214   \n",
      "\n",
      "   fBodyBodyGyroJerkMag-max()  fBodyBodyGyroJerkMag-min()  \n",
      "0                   -0.925076                   -0.942807  \n",
      "1                   -0.973749                   -0.963480  \n",
      "2                   -0.986690                   -0.991881  \n",
      "3                   -0.988878                   -0.982714  \n",
      "4                   -0.990152                   -0.993921  \n",
      "\n",
      "[5 rows x 87 columns]\n"
     ]
    }
   ],
   "source": [
    "# Save test dataset\n",
    "print(\"Saving test dataset...\")\n",
    "\n",
    "# Save full test dataset (all 561 features)\n",
    "output_file_test_full = 'X_test_recreated_full.txt'\n",
    "np.savetxt(output_file_test_full, X_test_recreated, fmt='%.16f')\n",
    "print(f\"Full test dataset (561 features) saved to {output_file_test_full}\")\n",
    "\n",
    "# Save filtered test dataset as CSV with headers\n",
    "output_file_test_csv = 'X_test_recreated_filtered.csv'\n",
    "df_test_filtered = pd.DataFrame(X_test_recreated_filtered, columns=desired_features)\n",
    "df_test_filtered.to_csv(output_file_test_csv, index=False)\n",
    "print(f\"Filtered test dataset ({len(desired_features)} features) saved to {output_file_test_csv}\")\n",
    "\n",
    "# Also save as TXT for backward compatibility\n",
    "output_file_test_txt = 'X_test_recreated_filtered.txt'\n",
    "np.savetxt(output_file_test_txt, X_test_recreated_filtered, fmt='%.16f')\n",
    "print(f\"Filtered test dataset ({len(desired_features)} features) also saved to {output_file_test_txt} (TXT format)\")\n",
    "\n",
    "# Display first few rows\n",
    "print(f\"\\nFirst 5 rows of test CSV (first 5 columns):\")\n",
    "print(df_test_filtered.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152aa375",
   "metadata": {},
   "source": [
    "## Verify Test Dataset (Optional)\n",
    "\n",
    "Compare the test dataset with the original to verify correctness.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "262f8bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading original X_test.txt...\n",
      "Original test dataset shape: (2947, 561)\n",
      "Recreated test dataset shape: (2947, 561)\n",
      "Filtered original test dataset shape: (2947, 87)\n",
      "Filtered recreated test dataset shape: (2947, 87)\n",
      "✓ Shapes match!\n",
      "\n",
      "============================================================\n",
      "TEST DATASET COMPARISON: DESIRED FEATURES ONLY (87 features)\n",
      "============================================================\n",
      "\n",
      "Mean correlation across desired features: 0.9637\n",
      "Median correlation: 0.9995\n",
      "Features with correlation > 0.9: 80/87\n",
      "Features with correlation > 0.95: 72/87\n",
      "Features with correlation > 0.99: 64/87\n",
      "Features with correlation > 0.999: 47/87\n",
      "\n",
      "Features with correlation < 0.9: 7\n",
      "Low-correlation test features:\n",
      "  Feature 357 (fBodyAccJerk-min()-X): correlation = 0.5444\n",
      "  Feature 358 (fBodyAccJerk-min()-Y): correlation = 0.5791\n",
      "  Feature 359 (fBodyAccJerk-min()-Z): correlation = 0.5656\n",
      "  Feature 433 (fBodyGyro-max()-X): correlation = 0.8035\n",
      "  Feature 520 (fBodyBodyAccJerkMag-min()): correlation = 0.6415\n",
      "  Feature 532 (fBodyBodyGyroMag-max()): correlation = 0.8987\n",
      "  Feature 546 (fBodyBodyGyroJerkMag-min()): correlation = 0.6616\n",
      "\n",
      "Mean Absolute Error (test, desired features): 0.029898\n",
      "Root Mean Square Error (test, desired features): 0.087693\n",
      "\n",
      "============================================================\n",
      "TEST DATASET SUMMARY\n",
      "============================================================\n",
      "Total desired features: 87\n",
      "Perfect matches (>0.999): 47\n",
      "Excellent matches (>0.99): 64\n",
      "Good matches (>0.95): 72\n",
      "Acceptable matches (>0.9): 80\n",
      "Poor matches (<0.9): 7\n",
      "\n",
      "Success rate (correlation > 0.9): 92.0%\n",
      "Original test dataset shape: (2947, 561)\n",
      "Recreated test dataset shape: (2947, 561)\n",
      "Filtered original test dataset shape: (2947, 87)\n",
      "Filtered recreated test dataset shape: (2947, 87)\n",
      "✓ Shapes match!\n",
      "\n",
      "============================================================\n",
      "TEST DATASET COMPARISON: DESIRED FEATURES ONLY (87 features)\n",
      "============================================================\n",
      "\n",
      "Mean correlation across desired features: 0.9637\n",
      "Median correlation: 0.9995\n",
      "Features with correlation > 0.9: 80/87\n",
      "Features with correlation > 0.95: 72/87\n",
      "Features with correlation > 0.99: 64/87\n",
      "Features with correlation > 0.999: 47/87\n",
      "\n",
      "Features with correlation < 0.9: 7\n",
      "Low-correlation test features:\n",
      "  Feature 357 (fBodyAccJerk-min()-X): correlation = 0.5444\n",
      "  Feature 358 (fBodyAccJerk-min()-Y): correlation = 0.5791\n",
      "  Feature 359 (fBodyAccJerk-min()-Z): correlation = 0.5656\n",
      "  Feature 433 (fBodyGyro-max()-X): correlation = 0.8035\n",
      "  Feature 520 (fBodyBodyAccJerkMag-min()): correlation = 0.6415\n",
      "  Feature 532 (fBodyBodyGyroMag-max()): correlation = 0.8987\n",
      "  Feature 546 (fBodyBodyGyroJerkMag-min()): correlation = 0.6616\n",
      "\n",
      "Mean Absolute Error (test, desired features): 0.029898\n",
      "Root Mean Square Error (test, desired features): 0.087693\n",
      "\n",
      "============================================================\n",
      "TEST DATASET SUMMARY\n",
      "============================================================\n",
      "Total desired features: 87\n",
      "Perfect matches (>0.999): 47\n",
      "Excellent matches (>0.99): 64\n",
      "Good matches (>0.95): 72\n",
      "Acceptable matches (>0.9): 80\n",
      "Poor matches (<0.9): 7\n",
      "\n",
      "Success rate (correlation > 0.9): 92.0%\n"
     ]
    }
   ],
   "source": [
    "# Load original X_test.txt and compare\n",
    "print(\"Loading original X_test.txt...\")\n",
    "try:\n",
    "    X_test_original = np.loadtxt('dataset/test/X_test.txt')\n",
    "    print(f\"Original test dataset shape: {X_test_original.shape}\")\n",
    "    print(f\"Recreated test dataset shape: {X_test_recreated.shape}\")\n",
    "    \n",
    "    # Filter original test dataset to only include desired features\n",
    "    X_test_original_filtered = X_test_original[:, desired_indices]\n",
    "    print(f\"Filtered original test dataset shape: {X_test_original_filtered.shape}\")\n",
    "    print(f\"Filtered recreated test dataset shape: {X_test_recreated_filtered.shape}\")\n",
    "    \n",
    "    # Compare shapes\n",
    "    if X_test_original_filtered.shape == X_test_recreated_filtered.shape:\n",
    "        print(\"✓ Shapes match!\")\n",
    "    else:\n",
    "        print(\"✗ Shapes do not match!\")\n",
    "    \n",
    "    # Calculate correlation for each desired feature\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"TEST DATASET COMPARISON: DESIRED FEATURES ONLY ({} features)\".format(len(desired_features)))\n",
    "    print('='*60)\n",
    "    \n",
    "    correlations_test = []\n",
    "    for i in range(X_test_original_filtered.shape[1]):\n",
    "        corr = np.corrcoef(X_test_original_filtered[:, i], X_test_recreated_filtered[:, i])[0, 1]\n",
    "        correlations_test.append(corr)\n",
    "    \n",
    "    correlations_test = np.array(correlations_test)\n",
    "    print(f\"\\nMean correlation across desired features: {np.nanmean(correlations_test):.4f}\")\n",
    "    print(f\"Median correlation: {np.nanmedian(correlations_test):.4f}\")\n",
    "    print(f\"Features with correlation > 0.9: {np.sum(correlations_test > 0.9)}/{len(correlations_test)}\")\n",
    "    print(f\"Features with correlation > 0.95: {np.sum(correlations_test > 0.95)}/{len(correlations_test)}\")\n",
    "    print(f\"Features with correlation > 0.99: {np.sum(correlations_test > 0.99)}/{len(correlations_test)}\")\n",
    "    print(f\"Features with correlation > 0.999: {np.sum(correlations_test > 0.999)}/{len(correlations_test)}\")\n",
    "    \n",
    "    # Find features with low correlation\n",
    "    low_corr_features_test = np.where(correlations_test < 0.9)[0]\n",
    "    if len(low_corr_features_test) > 0:\n",
    "        print(f\"\\nFeatures with correlation < 0.9: {len(low_corr_features_test)}\")\n",
    "        print(\"Low-correlation test features:\")\n",
    "        for idx in low_corr_features_test[:10]:  # Show first 10\n",
    "            orig_idx = desired_indices[idx]\n",
    "            print(f\"  Feature {orig_idx+1} ({desired_features[idx]}): correlation = {correlations_test[idx]:.4f}\")\n",
    "    else:\n",
    "        print(\"\\n✓ All desired test features have correlation ≥ 0.9!\")\n",
    "    \n",
    "    # Calculate mean absolute error\n",
    "    mae_test = np.mean(np.abs(X_test_original_filtered - X_test_recreated_filtered))\n",
    "    print(f\"\\nMean Absolute Error (test, desired features): {mae_test:.6f}\")\n",
    "    \n",
    "    # Calculate RMSE\n",
    "    rmse_test = np.sqrt(np.mean((X_test_original_filtered - X_test_recreated_filtered)**2))\n",
    "    print(f\"Root Mean Square Error (test, desired features): {rmse_test:.6f}\")\n",
    "    \n",
    "    # Summary statistics\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"TEST DATASET SUMMARY\")\n",
    "    print('='*60)\n",
    "    print(f\"Total desired features: {len(desired_features)}\")\n",
    "    print(f\"Perfect matches (>0.999): {np.sum(correlations_test > 0.999)}\")\n",
    "    print(f\"Excellent matches (>0.99): {np.sum(correlations_test > 0.99)}\")\n",
    "    print(f\"Good matches (>0.95): {np.sum(correlations_test > 0.95)}\")\n",
    "    print(f\"Acceptable matches (>0.9): {np.sum(correlations_test > 0.9)}\")\n",
    "    print(f\"Poor matches (<0.9): {len(low_corr_features_test)}\")\n",
    "    \n",
    "    success_rate_test = np.sum(correlations_test > 0.9) / len(correlations_test) * 100\n",
    "    print(f\"\\nSuccess rate (correlation > 0.9): {success_rate_test:.1f}%\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"Error: dataset/test/X_test.txt not found\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading original test dataset: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EE5127-Project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
